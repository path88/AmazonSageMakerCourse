{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Factorization Machines - Movie Recommendation Model</h2>\n",
    "Input Features: [userId, moveId] <br>\n",
    "Target: rating <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# SageMaker SDK Documentation: http://sagemaker.readthedocs.io/en/latest/estimators.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify your bucket name\n",
    "bucket_name = 'sagemaker-us-east-1-190250733572'\n",
    "training_file_key = 'movie/user_movie_train.recordio'\n",
    "test_file_key = 'movie/user_movie_test.recordio'\n",
    "\n",
    "s3_model_output_location = r's3://{0}/movie/model'.format(bucket_name)\n",
    "s3_training_file_location = r's3://{0}/{1}'.format(bucket_name,training_file_key)\n",
    "s3_test_file_location = r's3://{0}/{1}'.format(bucket_name,test_file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read Dimension: Number of unique users + Number of unique movies in our dataset\n",
    "dim_movie = 0\n",
    "\n",
    "# Update movie dimension - from file used for training \n",
    "with open(r'ml-latest-small/movie_dimension.txt','r') as f:\n",
    "    dim_movie = int(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10334"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-190250733572/movie/model\n",
      "s3://sagemaker-us-east-1-190250733572/movie/user_movie_train.recordio\n",
      "s3://sagemaker-us-east-1-190250733572/movie/user_movie_test.recordio\n"
     ]
    }
   ],
   "source": [
    "print(s3_model_output_location)\n",
    "print(s3_training_file_location)\n",
    "print(s3_test_file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write and Reading from S3 is just as easy\n",
    "# files are referred as objects in S3.  \n",
    "# file name is referred as key name in S3\n",
    "# Files stored in S3 are automatically replicated across 3 different availability zones \n",
    "# in the region where the bucket was created.\n",
    "\n",
    "# http://boto3.readthedocs.io/en/latest/guide/s3.html\n",
    "def write_to_s3(filename, bucket, key):\n",
    "    with open(filename,'rb') as f: # Read in binary mode\n",
    "        return boto3.Session().resource('s3').Bucket(bucket).Object(key).upload_fileobj(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_to_s3(r'ml-latest-small/user_movie_train.recordio',bucket_name,training_file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_to_s3(r'ml-latest-small/user_movie_test.recordio',bucket_name,test_file_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Algorithm Docker Image\n",
    "### AWS Maintains a separate image for every region and algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint uri: s3://sagemaker-us-east-1-190250733572/movie/checkpoints/fm-movie-v4\n"
     ]
    }
   ],
   "source": [
    "# Use Spot Instance - Save up to 90% of training cost by using spot instances when compared to on-demand instances\n",
    "# Reference: https://github.com/aws-samples/amazon-sagemaker-managed-spot-training/blob/main/xgboost_built_in_managed_spot_training_checkpointing/xgboost_built_in_managed_spot_training_checkpointing.ipynb\n",
    "\n",
    "# if you are still on two-month free-tier you can use the on-demand instance by setting:\n",
    "#   use_spot_instances = False\n",
    "\n",
    "# We will use spot for training\n",
    "use_spot_instances = True\n",
    "max_run = 3600 # in seconds\n",
    "max_wait = 3600 if use_spot_instances else None # in seconds\n",
    "\n",
    "job_name = 'fm-movie-v4'\n",
    "\n",
    "checkpoint_s3_uri = None\n",
    "\n",
    "if use_spot_instances:\n",
    "    checkpoint_s3_uri = f's3://{bucket_name}/movie/checkpoints/{job_name}'\n",
    "    \n",
    "print (f'Checkpoint uri: {checkpoint_s3_uri}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-us-east-1-190250733572'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::190250733572:role/sagemaker-operator\n"
     ]
    }
   ],
   "source": [
    "# This role contains the permissions needed to train, deploy models\n",
    "# SageMaker Service is trusted to assume this role\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FM Container 382416733822.dkr.ecr.us-east-1.amazonaws.com/factorization-machines:1\n"
     ]
    }
   ],
   "source": [
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/image_uris.html#sagemaker.image_uris.retrieve\n",
    "\n",
    "# SDK 2 uses image_uris.retrieve the container image location\n",
    "\n",
    "# Use factorization-machines\n",
    "container = sagemaker.image_uris.retrieve(\"factorization-machines\",sess.boto_region_name)\n",
    "\n",
    "print (f'Using FM Container {container}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'382416733822.dkr.ecr.us-east-1.amazonaws.com/factorization-machines:1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure the training job\n",
    "# Specify type and number of instances to use\n",
    "# S3 location where final artifacts needs to be stored\n",
    "\n",
    "#   Reference: http://sagemaker.readthedocs.io/en/latest/estimators.html\n",
    "\n",
    "# SDK 2.x version does not require train prefix for instance count and type\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(container,\n",
    "                                          role,                                        \n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.xlarge',\n",
    "                                          output_path=s3_model_output_location,\n",
    "                                          sagemaker_session=sess,\n",
    "                                          base_job_name = job_name,\n",
    "                                          use_spot_instances=use_spot_instances,\n",
    "                                          max_run=max_run,\n",
    "                                          max_wait=max_wait,\n",
    "                                          checkpoint_s3_uri=checkpoint_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Configuration after Model Tuning\n",
    "### Refer to Hyperparameter Tuning Lecture on how to optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(feature_dim=dim_movie,\n",
    "                              num_factors=8,\n",
    "                              predictor_type='regressor', \n",
    "                              mini_batch_size=994,\n",
    "                              epochs=91,\n",
    "                              bias_init_method='normal',\n",
    "                              bias_lr=0.21899531189430518,\n",
    "                              factors_init_method='normal',\n",
    "                              factors_lr=5.357593337770278e-05,\n",
    "                              linear_init_method='normal',\n",
    "                              linear_lr=0.00021524948053767607)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_dim': 10334,\n",
       " 'num_factors': 8,\n",
       " 'predictor_type': 'regressor',\n",
       " 'mini_batch_size': 994,\n",
       " 'epochs': 91,\n",
       " 'bias_init_method': 'normal',\n",
       " 'bias_lr': 0.21899531189430518,\n",
       " 'factors_init_method': 'normal',\n",
       " 'factors_lr': 5.357593337770278e-05,\n",
       " 'linear_init_method': 'normal',\n",
       " 'linear_lr': 0.00021524948053767607}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: fm-movie-v4-2024-01-25-02-30-45-220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-25 02:30:45 Starting - Starting the training job...\n",
      "2024-01-25 02:31:00 Starting - Preparing the instances for training.........\n",
      "2024-01-25 02:32:24 Downloading - Downloading input data...\n",
      "2024-01-25 02:32:49 Downloading - Downloading the training image.....................\n",
      "2024-01-25 02:36:40 Training - Training image download completed. Training in progress...\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-conf.json: {'epochs': 1, 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0'}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'bias_init_method': 'normal', 'bias_lr': '0.21899531189430518', 'epochs': '91', 'factors_init_method': 'normal', 'factors_lr': '5.357593337770278e-05', 'feature_dim': '10334', 'linear_init_method': 'normal', 'linear_lr': '0.00021524948053767607', 'mini_batch_size': '994', 'num_factors': '8', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] Final configuration: {'epochs': '91', 'mini_batch_size': '994', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.21899531189430518', 'linear_lr': '0.00021524948053767607', 'factors_lr': '5.357593337770278e-05', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0', 'feature_dim': '10334', 'num_factors': '8', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 WARNING 140081874167616] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] Using default worker.\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:36:56.064] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:36:56.068] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 7, \"num_examples\": 1, \"num_bytes\": 63616}\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] nvidia-smi: took 0.032 seconds to run.\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150216.0606625, \"EndTime\": 1706150216.1036077, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 36.82899475097656, \"count\": 1, \"min\": 36.82899475097656, \"max\": 36.82899475097656}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150216.1037183, \"EndTime\": 1706150216.1037571, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 994.0, \"count\": 1, \"min\": 994, \"max\": 994}, \"Total Batches Seen\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Max Records Seen Between Resets\": {\"sum\": 994.0, \"count\": 1, \"min\": 994, \"max\": 994}, \"Max Batches Seen Between Resets\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[02:36:56] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.398.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:306: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use kv.row_sparse_pull() or module.prepare() with row_ids.\u001b[0m\n",
      "\u001b[34m[02:36:56] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.398.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:306: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use kv.row_sparse_pull() or module.prepare() with row_ids.\u001b[0m\n",
      "\u001b[34m[02:36:56] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.398.0/AL2_x86_64/generic-flavor/src/src/operator/././../common/utils.h:450: Optimizer with lazy_update = True detected. Be aware that lazy update with row_sparse gradient is different from standard update, and may lead to different empirical results. See https://mxnet.incubator.apache.org/api/python/optimization/optimization.html for more details.\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=3.646887842133151\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=13.299790933098592\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=3.500805369325327\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:36:56.339] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 220, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=1.5197361996021286\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=0, train mse <loss>=2.309598116381121\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=1.1554540220107539\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150216.1036687, \"EndTime\": 1706150216.3397927, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"update.time\": {\"sum\": 235.81743240356445, \"count\": 1, \"min\": 235.81743240356445, \"max\": 235.81743240356445}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #progress_metric: host=algo-1, completed 1.098901098901099 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150216.1039512, \"EndTime\": 1706150216.3400002, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 71579.0, \"count\": 1, \"min\": 71579, \"max\": 71579}, \"Total Batches Seen\": {\"sum\": 73.0, \"count\": 1, \"min\": 73, \"max\": 73}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=298933.6791704111 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=1.0234240604966414\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=1.047396807603433\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=0.8189823756995096\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:36:56.562] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 220, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=1.1155756837454913\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=1, train mse <loss>=1.2445091061642206\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=0.8795603712266546\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150216.3398569, \"EndTime\": 1706150216.5627697, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 222.5656509399414, \"count\": 1, \"min\": 222.5656509399414, \"max\": 222.5656509399414}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #progress_metric: host=algo-1, completed 2.197802197802198 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150216.340182, \"EndTime\": 1706150216.5629992, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 142164.0, \"count\": 1, \"min\": 142164, \"max\": 142164}, \"Total Batches Seen\": {\"sum\": 145.0, \"count\": 1, \"min\": 145, \"max\": 145}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=316624.4555979188 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=1.0251199438229002\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=1.0508708992234659\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=0.82658352458501\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:36:56.789] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 224, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=1.1164356710480259\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=2, train mse <loss>=1.246428607588456\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=0.8795249362453476\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150216.562839, \"EndTime\": 1706150216.790149, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 226.823091506958, \"count\": 1, \"min\": 226.823091506958, \"max\": 226.823091506958}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #progress_metric: host=algo-1, completed 3.2967032967032965 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150216.5632422, \"EndTime\": 1706150216.7905543, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 212749.0, \"count\": 1, \"min\": 212749, \"max\": 212749}, \"Total Batches Seen\": {\"sum\": 217.0, \"count\": 1, \"min\": 217, \"max\": 217}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=310368.8487767342 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=1.0249226177880313\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=3, batch=0 train mse <loss>=1.0504663724534709\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:56 INFO 140081874167616] #quality_metric: host=algo-1, epoch=3, batch=0 train absolute_loss <loss>=0.8286705093844315\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:36:57.033] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 240, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=1.1143875756921624\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=3, train mse <loss>=1.2418596688570551\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=3, train absolute_loss <loss>=0.877086690573945\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150216.7902765, \"EndTime\": 1706150217.0341885, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 243.2703971862793, \"count\": 1, \"min\": 243.2703971862793, \"max\": 243.2703971862793}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #progress_metric: host=algo-1, completed 4.395604395604396 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150216.7908921, \"EndTime\": 1706150217.034501, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 283334.0, \"count\": 1, \"min\": 283334, \"max\": 283334}, \"Total Batches Seen\": {\"sum\": 289.0, \"count\": 1, \"min\": 289, \"max\": 289}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=289500.08687302103 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=1.0248812188293173\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=4, batch=0 train mse <loss>=1.050381512709067\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=4, batch=0 train absolute_loss <loss>=0.8302560111646441\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:36:57.313] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 275, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=1.1115614940453293\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=4, train mse <loss>=1.2355689550442848\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=4, train absolute_loss <loss>=0.8743470121810507\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150217.0342934, \"EndTime\": 1706150217.314267, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.37889099121094, \"count\": 1, \"min\": 279.37889099121094, \"max\": 279.37889099121094}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #progress_metric: host=algo-1, completed 5.4945054945054945 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150217.0348418, \"EndTime\": 1706150217.3146312, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 353919.0, \"count\": 1, \"min\": 353919, \"max\": 353919}, \"Total Batches Seen\": {\"sum\": 361.0, \"count\": 1, \"min\": 361, \"max\": 361}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=252151.36139870336 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=5, batch=0 train rmse <loss>=1.0236996550138573\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=5, batch=0 train mse <loss>=1.0479609836754904\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=5, batch=0 train absolute_loss <loss>=0.8298427036830357\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:36:57.546] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 229, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=5, train rmse <loss>=1.1083176315578191\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=5, train mse <loss>=1.2283679724219339\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=5, train absolute_loss <loss>=0.8714153077440883\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150217.3143504, \"EndTime\": 1706150217.547292, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 232.23876953125, \"count\": 1, \"min\": 232.23876953125, \"max\": 232.23876953125}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #progress_metric: host=algo-1, completed 6.593406593406593 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150217.3150177, \"EndTime\": 1706150217.5474968, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 424504.0, \"count\": 1, \"min\": 424504, \"max\": 424504}, \"Total Batches Seen\": {\"sum\": 433.0, \"count\": 1, \"min\": 433, \"max\": 433}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=303462.7777065957 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=6, batch=0 train rmse <loss>=1.021472198468817\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=6, batch=0 train mse <loss>=1.0434054522447183\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=6, batch=0 train absolute_loss <loss>=0.827937350666499\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:36:57.886] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 336, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=6, train rmse <loss>=1.1048948934682883\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=6, train mse <loss>=1.2207927256123001\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=6, train absolute_loss <loss>=0.8683295408778081\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150217.5473566, \"EndTime\": 1706150217.8869894, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 339.25509452819824, \"count\": 1, \"min\": 339.25509452819824, \"max\": 339.25509452819824}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #progress_metric: host=algo-1, completed 7.6923076923076925 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150217.5477107, \"EndTime\": 1706150217.887158, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 495089.0, \"count\": 1, \"min\": 495089, \"max\": 495089}, \"Total Batches Seen\": {\"sum\": 505.0, \"count\": 1, \"min\": 505, \"max\": 505}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=207881.12799519717 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=7, batch=0 train rmse <loss>=1.018587458468458\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=7, batch=0 train mse <loss>=1.0375204105492328\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:57 INFO 140081874167616] #quality_metric: host=algo-1, epoch=7, batch=0 train absolute_loss <loss>=0.8251580405283262\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:36:58.243] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 354, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #quality_metric: host=algo-1, epoch=7, train rmse <loss>=1.1014064001742032\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #quality_metric: host=algo-1, epoch=7, train mse <loss>=1.213096058344697\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #quality_metric: host=algo-1, epoch=7, train absolute_loss <loss>=0.8651623255769971\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150217.88705, \"EndTime\": 1706150218.2444952, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 357.0866584777832, \"count\": 1, \"min\": 357.0866584777832, \"max\": 357.0866584777832}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #progress_metric: host=algo-1, completed 8.791208791208792 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150217.8873544, \"EndTime\": 1706150218.244763, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 565674.0, \"count\": 1, \"min\": 565674, \"max\": 565674}, \"Total Batches Seen\": {\"sum\": 577.0, \"count\": 1, \"min\": 577, \"max\": 577}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=197406.81449870643 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #quality_metric: host=algo-1, epoch=8, batch=0 train rmse <loss>=1.0153375376730998\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #quality_metric: host=algo-1, epoch=8, batch=0 train mse <loss>=1.0309103154080734\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #quality_metric: host=algo-1, epoch=8, batch=0 train absolute_loss <loss>=0.8218921684403295\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:36:58.472] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 224, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #quality_metric: host=algo-1, epoch=8, train rmse <loss>=1.097900645645606\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #quality_metric: host=algo-1, epoch=8, train mse <loss>=1.2053858277090386\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #quality_metric: host=algo-1, epoch=8, train absolute_loss <loss>=0.8619507223121171\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150218.2445652, \"EndTime\": 1706150218.472845, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 227.71692276000977, \"count\": 1, \"min\": 227.71692276000977, \"max\": 227.71692276000977}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #progress_metric: host=algo-1, completed 9.89010989010989 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150218.2451043, \"EndTime\": 1706150218.4730566, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 636259.0, \"count\": 1, \"min\": 636259, \"max\": 636259}, \"Total Batches Seen\": {\"sum\": 649.0, \"count\": 1, \"min\": 649, \"max\": 649}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=309446.2335989966 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #quality_metric: host=algo-1, epoch=9, batch=0 train rmse <loss>=1.0118971849157024\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #quality_metric: host=algo-1, epoch=9, batch=0 train mse <loss>=1.0239359128403231\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #quality_metric: host=algo-1, epoch=9, batch=0 train absolute_loss <loss>=0.8183543399066273\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:36:58.741] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 265, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #quality_metric: host=algo-1, epoch=9, train rmse <loss>=1.0944008632151678\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #quality_metric: host=algo-1, epoch=9, train mse <loss>=1.1977132494061047\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #quality_metric: host=algo-1, epoch=9, train absolute_loss <loss>=0.8587238960769281\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150218.4729195, \"EndTime\": 1706150218.7424204, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 269.0927982330322, \"count\": 1, \"min\": 269.0927982330322, \"max\": 269.0927982330322}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #progress_metric: host=algo-1, completed 10.989010989010989 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150218.473303, \"EndTime\": 1706150218.7428691, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 706844.0, \"count\": 1, \"min\": 706844, \"max\": 706844}, \"Total Batches Seen\": {\"sum\": 721.0, \"count\": 1, \"min\": 721, \"max\": 721}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=261703.4864986948 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #quality_metric: host=algo-1, epoch=10, batch=0 train rmse <loss>=1.0083672757125401\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #quality_metric: host=algo-1, epoch=10, batch=0 train mse <loss>=1.01680456272793\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:58 INFO 140081874167616] #quality_metric: host=algo-1, epoch=10, batch=0 train absolute_loss <loss>=0.8146637392715669\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:36:59.006] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 260, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=10, train rmse <loss>=1.0909204291235222\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=10, train mse <loss>=1.1901073826790496\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=10, train absolute_loss <loss>=0.8554959347283789\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150218.7424927, \"EndTime\": 1706150219.0078883, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.3885612487793, \"count\": 1, \"min\": 264.3885612487793, \"max\": 264.3885612487793}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #progress_metric: host=algo-1, completed 12.087912087912088 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150218.7434745, \"EndTime\": 1706150219.0083048, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 777429.0, \"count\": 1, \"min\": 777429, \"max\": 777429}, \"Total Batches Seen\": {\"sum\": 793.0, \"count\": 1, \"min\": 793, \"max\": 793}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=266302.5605635931 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=11, batch=0 train rmse <loss>=1.0048066333722658\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=11, batch=0 train mse <loss>=1.009636370468907\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=11, batch=0 train absolute_loss <loss>=0.8108884631028358\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:36:59.278] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 267, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=11, train rmse <loss>=1.0874684160975043\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=11, train mse <loss>=1.1825875560096146\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=11, train absolute_loss <loss>=0.8522780597702971\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150219.0079563, \"EndTime\": 1706150219.2794588, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.6334590911865, \"count\": 1, \"min\": 270.6334590911865, \"max\": 270.6334590911865}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #progress_metric: host=algo-1, completed 13.186813186813186 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150219.0088007, \"EndTime\": 1706150219.2796724, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 848014.0, \"count\": 1, \"min\": 848014, \"max\": 848014}, \"Total Batches Seen\": {\"sum\": 865.0, \"count\": 1, \"min\": 865, \"max\": 865}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 13.0, \"count\": 1, \"min\": 13, \"max\": 13}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=260471.88379479328 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=12, batch=0 train rmse <loss>=1.0012504389043981\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=12, batch=0 train mse <loss>=1.00250244140625\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=12, batch=0 train absolute_loss <loss>=0.8070690991653043\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:36:59.502] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 219, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=12, train rmse <loss>=1.0840516296352656\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=12, train mse <loss>=1.1751679357148752\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=12, train absolute_loss <loss>=0.8490731435255958\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150219.2795296, \"EndTime\": 1706150219.5029635, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 223.0372428894043, \"count\": 1, \"min\": 223.0372428894043, \"max\": 223.0372428894043}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #progress_metric: host=algo-1, completed 14.285714285714286 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150219.2798996, \"EndTime\": 1706150219.5033238, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 918599.0, \"count\": 1, \"min\": 918599, \"max\": 918599}, \"Total Batches Seen\": {\"sum\": 937.0, \"count\": 1, \"min\": 937, \"max\": 937}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 14.0, \"count\": 1, \"min\": 14, \"max\": 14}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=315715.8357985168 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=13, batch=0 train rmse <loss>=0.997720188145768\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=13, batch=0 train mse <loss>=0.9954455738336268\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=13, batch=0 train absolute_loss <loss>=0.8032308229258363\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:36:59.745] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 239, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=13, train rmse <loss>=1.080675325879457\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=13, train mse <loss>=1.1678591599646708\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=13, train absolute_loss <loss>=0.8458918795978999\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150219.5030556, \"EndTime\": 1706150219.7463398, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 242.59066581726074, \"count\": 1, \"min\": 242.59066581726074, \"max\": 242.59066581726074}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #progress_metric: host=algo-1, completed 15.384615384615385 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150219.5037227, \"EndTime\": 1706150219.7468672, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 989184.0, \"count\": 1, \"min\": 989184, \"max\": 989184}, \"Total Batches Seen\": {\"sum\": 1009.0, \"count\": 1, \"min\": 1009, \"max\": 1009}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 15.0, \"count\": 1, \"min\": 15, \"max\": 15}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=289908.5957025111 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=14, batch=0 train rmse <loss>=0.9942294359399421\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=14, batch=0 train mse <loss>=0.9884921712894554\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=14, batch=0 train absolute_loss <loss>=0.7993898449289487\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:36:59.982] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 232, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=14, train rmse <loss>=1.077343775774561\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=14, train mse <loss>=1.1606696112001873\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=14, train absolute_loss <loss>=0.8427363557088516\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150219.7465794, \"EndTime\": 1706150219.9833179, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 235.78667640686035, \"count\": 1, \"min\": 235.78667640686035, \"max\": 235.78667640686035}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #progress_metric: host=algo-1, completed 16.483516483516482 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150219.7474413, \"EndTime\": 1706150219.9836118, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1059769.0, \"count\": 1, \"min\": 1059769, \"max\": 1059769}, \"Total Batches Seen\": {\"sum\": 1081.0, \"count\": 1, \"min\": 1081, \"max\": 1081}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=298710.7854332874 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=15, batch=0 train rmse <loss>=0.9907870283501268\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=15, batch=0 train mse <loss>=0.981658935546875\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:36:59 INFO 140081874167616] #quality_metric: host=algo-1, epoch=15, batch=0 train absolute_loss <loss>=0.795578340649365\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:00.244] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 258, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=15, train rmse <loss>=1.0740602951512663\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=15, train mse <loss>=1.1536055176204252\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=15, train absolute_loss <loss>=0.8396096147468579\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150219.9833891, \"EndTime\": 1706150220.2455387, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 261.2640857696533, \"count\": 1, \"min\": 261.2640857696533, \"max\": 261.2640857696533}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #progress_metric: host=algo-1, completed 17.582417582417584 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150219.9842527, \"EndTime\": 1706150220.2458887, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1130354.0, \"count\": 1, \"min\": 1130354, \"max\": 1130354}, \"Total Batches Seen\": {\"sum\": 1153.0, \"count\": 1, \"min\": 1153, \"max\": 1153}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 17.0, \"count\": 1, \"min\": 17, \"max\": 17}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=269671.87010057986 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=16, batch=0 train rmse <loss>=0.9873985392884947\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=16, batch=0 train mse <loss>=0.974955875389053\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=16, batch=0 train absolute_loss <loss>=0.7918195206394618\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:00.494] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 34, \"duration\": 246, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=16, train rmse <loss>=1.0708276131168524\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=16, train mse <loss>=1.1466717770135353\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=16, train absolute_loss <loss>=0.836511782930384\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150220.2455962, \"EndTime\": 1706150220.4949172, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 248.48413467407227, \"count\": 1, \"min\": 248.48413467407227, \"max\": 248.48413467407227}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #progress_metric: host=algo-1, completed 18.681318681318682 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150220.2464101, \"EndTime\": 1706150220.4951801, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1200939.0, \"count\": 1, \"min\": 1200939, \"max\": 1200939}, \"Total Batches Seen\": {\"sum\": 1225.0, \"count\": 1, \"min\": 1225, \"max\": 1225}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 18.0, \"count\": 1, \"min\": 18, \"max\": 18}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=283598.18132354465 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=17, batch=0 train rmse <loss>=0.9840678016232671\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=17, batch=0 train mse <loss>=0.9683894381916499\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=17, batch=0 train absolute_loss <loss>=0.7880852620606451\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:00.703] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 36, \"duration\": 206, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=17, train rmse <loss>=1.0676478214379697\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=17, train mse <loss>=1.1398718706212427\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=17, train absolute_loss <loss>=0.8334454042437677\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150220.4950078, \"EndTime\": 1706150220.704413, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 208.7852954864502, \"count\": 1, \"min\": 208.7852954864502, \"max\": 208.7852954864502}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #progress_metric: host=algo-1, completed 19.78021978021978 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150220.4956043, \"EndTime\": 1706150220.704624, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1271524.0, \"count\": 1, \"min\": 1271524, \"max\": 1271524}, \"Total Batches Seen\": {\"sum\": 1297.0, \"count\": 1, \"min\": 1297, \"max\": 1297}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 19.0, \"count\": 1, \"min\": 19, \"max\": 19}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=337538.0347759266 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=18, batch=0 train rmse <loss>=0.9807970940759675\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=18, batch=0 train mse <loss>=0.9619629397478622\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=18, batch=0 train absolute_loss <loss>=0.7844097053021253\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:00.916] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 38, \"duration\": 210, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=18, train rmse <loss>=1.0645224832202624\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=18, train mse <loss>=1.133208117281434\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=18, train absolute_loss <loss>=0.8304129484753574\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150220.7044802, \"EndTime\": 1706150220.9179704, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 212.91708946228027, \"count\": 1, \"min\": 212.91708946228027, \"max\": 212.91708946228027}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #progress_metric: host=algo-1, completed 20.87912087912088 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150220.7050297, \"EndTime\": 1706150220.9183981, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1342109.0, \"count\": 1, \"min\": 1342109, \"max\": 1342109}, \"Total Batches Seen\": {\"sum\": 1369.0, \"count\": 1, \"min\": 1369, \"max\": 1369}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=330538.36250872246 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=19, batch=0 train rmse <loss>=0.9775879299385011\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=19, batch=0 train mse <loss>=0.9556781607614436\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:00 INFO 140081874167616] #quality_metric: host=algo-1, epoch=19, batch=0 train absolute_loss <loss>=0.7807944468569228\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:01.172] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 40, \"duration\": 251, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=19, train rmse <loss>=1.061452862025449\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=19, train mse <loss>=1.126682178302017\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=19, train absolute_loss <loss>=0.827415849228127\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150220.9181027, \"EndTime\": 1706150221.173467, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 254.34470176696777, \"count\": 1, \"min\": 254.34470176696777, \"max\": 254.34470176696777}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #progress_metric: host=algo-1, completed 21.978021978021978 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150220.9190986, \"EndTime\": 1706150221.1736765, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1412694.0, \"count\": 1, \"min\": 1412694, \"max\": 1412694}, \"Total Batches Seen\": {\"sum\": 1441.0, \"count\": 1, \"min\": 1441, \"max\": 1441}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 21.0, \"count\": 1, \"min\": 21, \"max\": 21}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=277138.57712009107 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=20, batch=0 train rmse <loss>=0.9744412638387956\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=20, batch=0 train mse <loss>=0.9495357766717493\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=20, batch=0 train absolute_loss <loss>=0.777328828930615\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:01.406] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 42, \"duration\": 230, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=20, train rmse <loss>=1.0584396851427709\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=20, train mse <loss>=1.1202945670851279\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=20, train absolute_loss <loss>=0.8244568304330104\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150221.1735342, \"EndTime\": 1706150221.40685, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 232.7415943145752, \"count\": 1, \"min\": 232.7415943145752, \"max\": 232.7415943145752}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #progress_metric: host=algo-1, completed 23.076923076923077 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150221.174085, \"EndTime\": 1706150221.4070568, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1483279.0, \"count\": 1, \"min\": 1483279, \"max\": 1483279}, \"Total Batches Seen\": {\"sum\": 1513.0, \"count\": 1, \"min\": 1513, \"max\": 1513}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 22.0, \"count\": 1, \"min\": 22, \"max\": 22}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=302836.0527327927 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=21, batch=0 train rmse <loss>=0.9713573554770788\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=21, batch=0 train mse <loss>=0.9435351120394241\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=21, batch=0 train absolute_loss <loss>=0.7739536584742832\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:01.642] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 44, \"duration\": 233, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=21, train rmse <loss>=1.0554835188009322\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=21, train mse <loss>=1.1140454584603978\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=21, train absolute_loss <loss>=0.8215354690875832\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150221.4069154, \"EndTime\": 1706150221.6427746, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 235.23426055908203, \"count\": 1, \"min\": 235.23426055908203, \"max\": 235.23426055908203}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #progress_metric: host=algo-1, completed 24.175824175824175 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150221.407518, \"EndTime\": 1706150221.6429858, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1553864.0, \"count\": 1, \"min\": 1553864, \"max\": 1553864}, \"Total Batches Seen\": {\"sum\": 1585.0, \"count\": 1, \"min\": 1585, \"max\": 1585}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=299615.88260475756 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=22, batch=0 train rmse <loss>=0.9683363605764167\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=22, batch=0 train mse <loss>=0.9376753072143801\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=22, batch=0 train absolute_loss <loss>=0.7706397687885124\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:01.879] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 46, \"duration\": 234, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=22, train rmse <loss>=1.0525846573934177\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=22, train mse <loss>=1.1079344609800186\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=22, train absolute_loss <loss>=0.8186551449471023\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150221.6428447, \"EndTime\": 1706150221.8811207, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 237.58578300476074, \"count\": 1, \"min\": 237.58578300476074, \"max\": 237.58578300476074}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #progress_metric: host=algo-1, completed 25.274725274725274 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150221.643488, \"EndTime\": 1706150221.8813825, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1624449.0, \"count\": 1, \"min\": 1624449, \"max\": 1624449}, \"Total Batches Seen\": {\"sum\": 1657.0, \"count\": 1, \"min\": 1657, \"max\": 1657}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 24.0, \"count\": 1, \"min\": 24, \"max\": 24}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=296402.9248738018 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=23, batch=0 train rmse <loss>=0.96537797928917\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=23, batch=0 train mse <loss>=0.9319546428964411\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:01 INFO 140081874167616] #quality_metric: host=algo-1, epoch=23, batch=0 train absolute_loss <loss>=0.7674092037577025\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:02.158] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 48, \"duration\": 272, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=23, train rmse <loss>=1.0497430630281512\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=23, train mse <loss>=1.1019604983757252\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=23, train absolute_loss <loss>=0.8158205894983617\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150221.8812127, \"EndTime\": 1706150222.1595192, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 277.32157707214355, \"count\": 1, \"min\": 277.32157707214355, \"max\": 277.32157707214355}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #progress_metric: host=algo-1, completed 26.373626373626372 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150221.8821716, \"EndTime\": 1706150222.1599429, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1695034.0, \"count\": 1, \"min\": 1695034, \"max\": 1695034}, \"Total Batches Seen\": {\"sum\": 1729.0, \"count\": 1, \"min\": 1729, \"max\": 1729}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 25.0, \"count\": 1, \"min\": 25, \"max\": 25}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=253877.95011023633 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=24, batch=0 train rmse <loss>=0.9624820553149653\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=24, batch=0 train mse <loss>=0.9263717068033199\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=24, batch=0 train absolute_loss <loss>=0.7643423406650842\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:02.416] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 50, \"duration\": 253, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=24, train rmse <loss>=1.0469586981824734\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=24, train mse <loss>=1.0961225156999397\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=24, train absolute_loss <loss>=0.8130323630490081\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150222.1596613, \"EndTime\": 1706150222.418025, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 257.190465927124, \"count\": 1, \"min\": 257.190465927124, \"max\": 257.190465927124}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #progress_metric: host=algo-1, completed 27.47252747252747 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150222.1607873, \"EndTime\": 1706150222.4186494, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1765619.0, \"count\": 1, \"min\": 1765619, \"max\": 1765619}, \"Total Batches Seen\": {\"sum\": 1801.0, \"count\": 1, \"min\": 1801, \"max\": 1801}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 26.0, \"count\": 1, \"min\": 26, \"max\": 26}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=273315.8860668927 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=25, batch=0 train rmse <loss>=0.9596478103891825\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=25, batch=0 train mse <loss>=0.9209239199847523\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=25, batch=0 train absolute_loss <loss>=0.7614038724534709\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:02.704] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 52, \"duration\": 282, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=25, train rmse <loss>=1.044231264383609\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=25, train mse <loss>=1.0904189335161905\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=25, train absolute_loss <loss>=0.8102913806829147\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150222.4183183, \"EndTime\": 1706150222.7047546, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 285.1402759552002, \"count\": 1, \"min\": 285.1402759552002, \"max\": 285.1402759552002}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #progress_metric: host=algo-1, completed 28.571428571428573 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150222.419591, \"EndTime\": 1706150222.704909, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1836204.0, \"count\": 1, \"min\": 1836204, \"max\": 1836204}, \"Total Batches Seen\": {\"sum\": 1873.0, \"count\": 1, \"min\": 1873, \"max\": 1873}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 27.0, \"count\": 1, \"min\": 27, \"max\": 27}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=247308.05677005454 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=26, batch=0 train rmse <loss>=0.9568745412546031\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=26, batch=0 train mse <loss>=0.9156088877012073\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=26, batch=0 train absolute_loss <loss>=0.7586485711141852\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:02.958] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 54, \"duration\": 250, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=26, train rmse <loss>=1.0415602557903847\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=26, train mse <loss>=1.0848477664421314\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=26, train absolute_loss <loss>=0.8076024037358374\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150222.7048125, \"EndTime\": 1706150222.958845, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 253.42893600463867, \"count\": 1, \"min\": 253.42893600463867, \"max\": 253.42893600463867}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #progress_metric: host=algo-1, completed 29.67032967032967 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150222.7053926, \"EndTime\": 1706150222.959034, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1906789.0, \"count\": 1, \"min\": 1906789, \"max\": 1906789}, \"Total Batches Seen\": {\"sum\": 1945.0, \"count\": 1, \"min\": 1945, \"max\": 1945}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=278167.39359488117 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=27, batch=0 train rmse <loss>=0.9541618142879925\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=27, batch=0 train mse <loss>=0.9104247678453534\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:02 INFO 140081874167616] #quality_metric: host=algo-1, epoch=27, batch=0 train absolute_loss <loss>=0.7560096909582495\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:03.296] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 56, \"duration\": 334, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #quality_metric: host=algo-1, epoch=27, train rmse <loss>=1.0389452875529497\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #quality_metric: host=algo-1, epoch=27, train mse <loss>=1.0794073105284812\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #quality_metric: host=algo-1, epoch=27, train absolute_loss <loss>=0.8049677442230423\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150222.9589067, \"EndTime\": 1706150223.2968218, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 337.3599052429199, \"count\": 1, \"min\": 337.3599052429199, \"max\": 337.3599052429199}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #progress_metric: host=algo-1, completed 30.76923076923077 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150222.959436, \"EndTime\": 1706150223.2972054, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1977374.0, \"count\": 1, \"min\": 1977374, \"max\": 1977374}, \"Total Batches Seen\": {\"sum\": 2017.0, \"count\": 1, \"min\": 2017, \"max\": 2017}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 29.0, \"count\": 1, \"min\": 29, \"max\": 29}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=208887.61028241867 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #quality_metric: host=algo-1, epoch=28, batch=0 train rmse <loss>=0.9515083403821737\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #quality_metric: host=algo-1, epoch=28, batch=0 train mse <loss>=0.9053681218168386\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #quality_metric: host=algo-1, epoch=28, batch=0 train absolute_loss <loss>=0.753450205628301\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:03.626] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 58, \"duration\": 325, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #quality_metric: host=algo-1, epoch=28, train rmse <loss>=1.036385629770208\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #quality_metric: host=algo-1, epoch=28, train mse <loss>=1.074095173594191\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #quality_metric: host=algo-1, epoch=28, train absolute_loss <loss>=0.8023887513175844\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150223.296936, \"EndTime\": 1706150223.6270213, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 329.0717601776123, \"count\": 1, \"min\": 329.0717601776123, \"max\": 329.0717601776123}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #progress_metric: host=algo-1, completed 31.86813186813187 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150223.2979233, \"EndTime\": 1706150223.6292539, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2047959.0, \"count\": 1, \"min\": 2047959, \"max\": 2047959}, \"Total Batches Seen\": {\"sum\": 2089.0, \"count\": 1, \"min\": 2089, \"max\": 2089}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 30.0, \"count\": 1, \"min\": 30, \"max\": 30}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=212948.57299867293 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #quality_metric: host=algo-1, epoch=29, batch=0 train rmse <loss>=0.9489134841967641\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #quality_metric: host=algo-1, epoch=29, batch=0 train mse <loss>=0.9004368004904426\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #quality_metric: host=algo-1, epoch=29, batch=0 train absolute_loss <loss>=0.7509918519908514\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:03.962] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 60, \"duration\": 330, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #quality_metric: host=algo-1, epoch=29, train rmse <loss>=1.033880644828907\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #quality_metric: host=algo-1, epoch=29, train mse <loss>=1.0689091877518366\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #quality_metric: host=algo-1, epoch=29, train absolute_loss <loss>=0.7998662966091361\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150223.629082, \"EndTime\": 1706150223.96305, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 333.301305770874, \"count\": 1, \"min\": 333.301305770874, \"max\": 333.301305770874}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #progress_metric: host=algo-1, completed 32.967032967032964 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150223.6297235, \"EndTime\": 1706150223.9632187, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2118544.0, \"count\": 1, \"min\": 2118544, \"max\": 2118544}, \"Total Batches Seen\": {\"sum\": 2161.0, \"count\": 1, \"min\": 2161, \"max\": 2161}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 31.0, \"count\": 1, \"min\": 31, \"max\": 31}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=211419.94836883363 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #quality_metric: host=algo-1, epoch=30, batch=0 train rmse <loss>=0.946376203154968\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #quality_metric: host=algo-1, epoch=30, batch=0 train mse <loss>=0.8956279178980131\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:03 INFO 140081874167616] #quality_metric: host=algo-1, epoch=30, batch=0 train absolute_loss <loss>=0.7486017177282445\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:04.256] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 62, \"duration\": 290, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=30, train rmse <loss>=1.0314295185122702\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=30, train mse <loss>=1.0638468516584534\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=30, train absolute_loss <loss>=0.797399377172595\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150223.963111, \"EndTime\": 1706150224.2569299, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 293.2274341583252, \"count\": 1, \"min\": 293.2274341583252, \"max\": 293.2274341583252}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #progress_metric: host=algo-1, completed 34.065934065934066 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150223.9636812, \"EndTime\": 1706150224.2571177, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 30, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2189129.0, \"count\": 1, \"min\": 2189129, \"max\": 2189129}, \"Total Batches Seen\": {\"sum\": 2233.0, \"count\": 1, \"min\": 2233, \"max\": 2233}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 32.0, \"count\": 1, \"min\": 32, \"max\": 32}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=240459.8980346864 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=31, batch=0 train rmse <loss>=0.9438954002789819\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=31, batch=0 train mse <loss>=0.8909385266678194\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=31, batch=0 train absolute_loss <loss>=0.7462684431786029\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:04.457] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 64, \"duration\": 198, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=31, train rmse <loss>=1.029031407042855\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=31, train mse <loss>=1.058905636680598\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=31, train absolute_loss <loss>=0.7949891400609058\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150224.2569935, \"EndTime\": 1706150224.458845, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 201.4780044555664, \"count\": 1, \"min\": 201.4780044555664, \"max\": 201.4780044555664}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #progress_metric: host=algo-1, completed 35.16483516483517 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150224.2573419, \"EndTime\": 1706150224.4592419, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 31, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2259714.0, \"count\": 1, \"min\": 2259714, \"max\": 2259714}, \"Total Batches Seen\": {\"sum\": 2305.0, \"count\": 1, \"min\": 2305, \"max\": 2305}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=349350.86824718595 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=32, batch=0 train rmse <loss>=0.9414703154467942\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=32, batch=0 train mse <loss>=0.8863663548674862\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=32, batch=0 train absolute_loss <loss>=0.7439898792167065\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:04.662] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 66, \"duration\": 200, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=32, train rmse <loss>=1.0266855538765831\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=32, train mse <loss>=1.0540832265388664\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=32, train absolute_loss <loss>=0.7926374180002977\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150224.4589558, \"EndTime\": 1706150224.6634543, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 203.72962951660156, \"count\": 1, \"min\": 203.72962951660156, \"max\": 203.72962951660156}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #progress_metric: host=algo-1, completed 36.26373626373626 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150224.459699, \"EndTime\": 1706150224.66368, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 32, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2330299.0, \"count\": 1, \"min\": 2330299, \"max\": 2330299}, \"Total Batches Seen\": {\"sum\": 2377.0, \"count\": 1, \"min\": 2377, \"max\": 2377}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 34.0, \"count\": 1, \"min\": 34, \"max\": 34}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=345844.0390824685 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=33, batch=0 train rmse <loss>=0.9390995495136079\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=33, batch=0 train mse <loss>=0.8819079638966613\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=33, batch=0 train absolute_loss <loss>=0.7417611749599158\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:04.870] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 68, \"duration\": 204, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=33, train rmse <loss>=1.0243909493628607\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=33, train mse <loss>=1.0493768171365432\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=33, train absolute_loss <loss>=0.7903423714419219\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150224.6635194, \"EndTime\": 1706150224.870841, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 206.9113254547119, \"count\": 1, \"min\": 206.9113254547119, \"max\": 206.9113254547119}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #progress_metric: host=algo-1, completed 37.362637362637365 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150224.6639078, \"EndTime\": 1706150224.8710144, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 33, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2400884.0, \"count\": 1, \"min\": 2400884, \"max\": 2400884}, \"Total Batches Seen\": {\"sum\": 2449.0, \"count\": 1, \"min\": 2449, \"max\": 2449}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 35.0, \"count\": 1, \"min\": 35, \"max\": 35}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=340662.2900914439 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=34, batch=0 train rmse <loss>=0.9367822039365585\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=34, batch=0 train mse <loss>=0.8775608976122359\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:04 INFO 140081874167616] #quality_metric: host=algo-1, epoch=34, batch=0 train absolute_loss <loss>=0.7395937514736859\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:05.081] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 70, \"duration\": 209, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=34, train rmse <loss>=1.0221466545807802\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=34, train mse <loss>=1.0447837834706808\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=34, train absolute_loss <loss>=0.7881022085952674\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150224.8709004, \"EndTime\": 1706150225.0824385, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 211.22479438781738, \"count\": 1, \"min\": 211.22479438781738, \"max\": 211.22479438781738}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #progress_metric: host=algo-1, completed 38.46153846153846 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150224.871193, \"EndTime\": 1706150225.0825863, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 34, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2471469.0, \"count\": 1, \"min\": 2471469, \"max\": 2471469}, \"Total Batches Seen\": {\"sum\": 2521.0, \"count\": 1, \"min\": 2521, \"max\": 2521}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 36.0, \"count\": 1, \"min\": 36, \"max\": 36}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=333773.33763249806 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=35, batch=0 train rmse <loss>=0.9345170991707321\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=35, batch=0 train mse <loss>=0.8733222086424799\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=35, batch=0 train absolute_loss <loss>=0.7374591174979565\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:05.292] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 72, \"duration\": 208, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=35, train rmse <loss>=1.0199518356302273\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=35, train mse <loss>=1.0403017470054703\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=35, train absolute_loss <loss>=0.7859172390367051\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150225.0824935, \"EndTime\": 1706150225.2931845, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 210.4179859161377, \"count\": 1, \"min\": 210.4179859161377, \"max\": 210.4179859161377}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #progress_metric: host=algo-1, completed 39.56043956043956 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150225.0827465, \"EndTime\": 1706150225.2933764, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 35, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2542054.0, \"count\": 1, \"min\": 2542054, \"max\": 2542054}, \"Total Batches Seen\": {\"sum\": 2593.0, \"count\": 1, \"min\": 2593, \"max\": 2593}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=334975.0261820387 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=36, batch=0 train rmse <loss>=0.9323031011547791\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=36, batch=0 train mse <loss>=0.8691890724228182\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=36, batch=0 train absolute_loss <loss>=0.7353585625078597\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:05.506] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 74, \"duration\": 211, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=36, train rmse <loss>=1.017805385207667\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=36, train mse <loss>=1.0359278021577272\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=36, train absolute_loss <loss>=0.783783376017007\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150225.2932408, \"EndTime\": 1706150225.5072725, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 213.70720863342285, \"count\": 1, \"min\": 213.70720863342285, \"max\": 213.70720863342285}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #progress_metric: host=algo-1, completed 40.65934065934066 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150225.2935407, \"EndTime\": 1706150225.5074942, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 36, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2612639.0, \"count\": 1, \"min\": 2612639, \"max\": 2612639}, \"Total Batches Seen\": {\"sum\": 2665.0, \"count\": 1, \"min\": 2665, \"max\": 2665}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 38.0, \"count\": 1, \"min\": 38, \"max\": 38}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=329739.4849222305 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=37, batch=0 train rmse <loss>=0.9301392215182437\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=37, batch=0 train mse <loss>=0.8651589714065644\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=37, batch=0 train absolute_loss <loss>=0.7332794373663858\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:05.725] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 76, \"duration\": 216, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=37, train rmse <loss>=1.0157063421031185\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=37, train mse <loss>=1.0316593733884971\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=37, train absolute_loss <loss>=0.7817019277735096\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150225.50734, \"EndTime\": 1706150225.7262142, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 218.45340728759766, \"count\": 1, \"min\": 218.45340728759766, \"max\": 218.45340728759766}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #progress_metric: host=algo-1, completed 41.75824175824176 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150225.5077345, \"EndTime\": 1706150225.7264457, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 37, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2683224.0, \"count\": 1, \"min\": 2683224, \"max\": 2683224}, \"Total Batches Seen\": {\"sum\": 2737.0, \"count\": 1, \"min\": 2737, \"max\": 2737}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 39.0, \"count\": 1, \"min\": 39, \"max\": 39}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=322556.1621197594 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=38, batch=0 train rmse <loss>=0.9280242228638153\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=38, batch=0 train mse <loss>=0.8612289582219882\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=38, batch=0 train absolute_loss <loss>=0.7312380754252075\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:05.936] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 78, \"duration\": 208, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=38, train rmse <loss>=1.0136537455465822\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=38, train mse <loss>=1.0274939158606151\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=38, train absolute_loss <loss>=0.779673009437921\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150225.7262855, \"EndTime\": 1706150225.9370809, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 210.3729248046875, \"count\": 1, \"min\": 210.3729248046875, \"max\": 210.3729248046875}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #progress_metric: host=algo-1, completed 42.857142857142854 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150225.7266858, \"EndTime\": 1706150225.937266, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 38, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2753809.0, \"count\": 1, \"min\": 2753809, \"max\": 2753809}, \"Total Batches Seen\": {\"sum\": 2809.0, \"count\": 1, \"min\": 2809, \"max\": 2809}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 40.0, \"count\": 1, \"min\": 40, \"max\": 40}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=335029.61275049 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=39, batch=0 train rmse <loss>=0.9259569149288289\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=39, batch=0 train mse <loss>=0.8573962083045146\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:05 INFO 140081874167616] #quality_metric: host=algo-1, epoch=39, batch=0 train absolute_loss <loss>=0.7292312222947057\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:06.151] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 80, \"duration\": 212, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=39, train rmse <loss>=1.011646545877785\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=39, train mse <loss>=1.0234287337864536\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=39, train absolute_loss <loss>=0.7776933273905586\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150225.9371414, \"EndTime\": 1706150226.1520329, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 214.33758735656738, \"count\": 1, \"min\": 214.33758735656738, \"max\": 214.33758735656738}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #progress_metric: host=algo-1, completed 43.956043956043956 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150225.937671, \"EndTime\": 1706150226.152271, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 39, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2824394.0, \"count\": 1, \"min\": 2824394, \"max\": 2824394}, \"Total Batches Seen\": {\"sum\": 2881.0, \"count\": 1, \"min\": 2881, \"max\": 2881}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 41.0, \"count\": 1, \"min\": 41, \"max\": 41}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=328729.69315003394 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=40, batch=0 train rmse <loss>=0.9239362886644484\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=40, batch=0 train mse <loss>=0.853658265511035\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=40, batch=0 train absolute_loss <loss>=0.7272519393705986\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:06.354] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 82, \"duration\": 200, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=40, train rmse <loss>=1.0096837523553426\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=40, train mse <loss>=1.0194612797703648\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=40, train absolute_loss <loss>=0.775761929875968\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150226.152104, \"EndTime\": 1706150226.3554683, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 202.68797874450684, \"count\": 1, \"min\": 202.68797874450684, \"max\": 202.68797874450684}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #progress_metric: host=algo-1, completed 45.05494505494506 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150226.1527538, \"EndTime\": 1706150226.3557017, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 40, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2894979.0, \"count\": 1, \"min\": 2894979, \"max\": 2894979}, \"Total Batches Seen\": {\"sum\": 2953.0, \"count\": 1, \"min\": 2953, \"max\": 2953}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 42.0, \"count\": 1, \"min\": 42, \"max\": 42}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=347598.1992119439 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=41, batch=0 train rmse <loss>=0.9219613522821976\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=41, batch=0 train mse <loss>=0.8500127351020184\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=41, batch=0 train absolute_loss <loss>=0.7253031740246164\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:06.573] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 84, \"duration\": 216, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=41, train rmse <loss>=1.0077643766397704\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=41, train mse <loss>=1.0155890388241449\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=41, train absolute_loss <loss>=0.7738766106294888\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150226.3555326, \"EndTime\": 1706150226.5749996, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 218.79959106445312, \"count\": 1, \"min\": 218.79959106445312, \"max\": 218.79959106445312}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #progress_metric: host=algo-1, completed 46.15384615384615 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150226.356176, \"EndTime\": 1706150226.5754168, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 41, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2965564.0, \"count\": 1, \"min\": 2965564, \"max\": 2965564}, \"Total Batches Seen\": {\"sum\": 3025.0, \"count\": 1, \"min\": 3025, \"max\": 3025}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=321801.65462308365 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=42, batch=0 train rmse <loss>=0.9200306981264273\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=42, batch=0 train mse <loss>=0.8464564854950013\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=42, batch=0 train absolute_loss <loss>=0.7233960403043259\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:06.804] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 86, \"duration\": 226, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=42, train rmse <loss>=1.0058873700846138\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=42, train mse <loss>=1.011809401295741\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=42, train absolute_loss <loss>=0.7720358635578117\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150226.57506, \"EndTime\": 1706150226.805175, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 229.29143905639648, \"count\": 1, \"min\": 229.29143905639648, \"max\": 229.29143905639648}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #progress_metric: host=algo-1, completed 47.252747252747255 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150226.5758588, \"EndTime\": 1706150226.8053653, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 42, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3036149.0, \"count\": 1, \"min\": 3036149, \"max\": 3036149}, \"Total Batches Seen\": {\"sum\": 3097.0, \"count\": 1, \"min\": 3097, \"max\": 3097}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 44.0, \"count\": 1, \"min\": 44, \"max\": 44}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=307399.20822015667 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=43, batch=0 train rmse <loss>=0.9181434017413543\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=43, batch=0 train mse <loss>=0.8429873061611859\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:06 INFO 140081874167616] #quality_metric: host=algo-1, epoch=43, batch=0 train absolute_loss <loss>=0.7215306610168826\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:07.011] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 88, \"duration\": 204, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=43, train rmse <loss>=1.0040517280821784\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=43, train mse <loss>=1.0081198726648084\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=43, train absolute_loss <loss>=0.7702385484306119\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150226.8052402, \"EndTime\": 1706150227.0116398, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 206.0093879699707, \"count\": 1, \"min\": 206.0093879699707, \"max\": 206.0093879699707}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #progress_metric: host=algo-1, completed 48.35164835164835 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150226.805606, \"EndTime\": 1706150227.011822, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 43, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3106734.0, \"count\": 1, \"min\": 3106734, \"max\": 3106734}, \"Total Batches Seen\": {\"sum\": 3169.0, \"count\": 1, \"min\": 3169, \"max\": 3169}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=342105.81106784224 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=44, batch=0 train rmse <loss>=0.9162983907862458\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=44, batch=0 train mse <loss>=0.8396027409574636\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=44, batch=0 train absolute_loss <loss>=0.7196975800113179\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:07.227] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 90, \"duration\": 213, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=44, train rmse <loss>=1.0022564738776256\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=44, train mse <loss>=1.0045180394296116\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=44, train absolute_loss <loss>=0.7684810339085293\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150227.0116973, \"EndTime\": 1706150227.2281327, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 216.07637405395508, \"count\": 1, \"min\": 216.07637405395508, \"max\": 216.07637405395508}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #progress_metric: host=algo-1, completed 49.45054945054945 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150227.0120325, \"EndTime\": 1706150227.2283475, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 44, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3177319.0, \"count\": 1, \"min\": 3177319, \"max\": 3177319}, \"Total Batches Seen\": {\"sum\": 3241.0, \"count\": 1, \"min\": 3241, \"max\": 3241}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 46.0, \"count\": 1, \"min\": 46, \"max\": 46}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=326152.998882913 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=45, batch=0 train rmse <loss>=0.9144946454451666\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=45, batch=0 train mse <loss>=0.836300456547881\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=45, batch=0 train absolute_loss <loss>=0.7178969200947874\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:07.427] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 92, \"duration\": 197, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=45, train rmse <loss>=1.000500601686634\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=45, train mse <loss>=1.0010014539753167\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=45, train absolute_loss <loss>=0.7667666076414542\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150227.2281995, \"EndTime\": 1706150227.428127, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 199.56588745117188, \"count\": 1, \"min\": 199.56588745117188, \"max\": 199.56588745117188}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #progress_metric: host=algo-1, completed 50.54945054945055 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150227.2285383, \"EndTime\": 1706150227.428314, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 45, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3247904.0, \"count\": 1, \"min\": 3247904, \"max\": 3247904}, \"Total Batches Seen\": {\"sum\": 3313.0, \"count\": 1, \"min\": 3313, \"max\": 3313}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 47.0, \"count\": 1, \"min\": 47, \"max\": 47}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=353149.30175301316 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=46, batch=0 train rmse <loss>=0.9127308294148312\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=46, batch=0 train mse <loss>=0.8330775669642857\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=46, batch=0 train absolute_loss <loss>=0.7161548391913984\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:07.637] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 94, \"duration\": 207, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=46, train rmse <loss>=0.9987830930594666\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=46, train mse <loss>=0.9975676669814351\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=46, train absolute_loss <loss>=0.7650959808874951\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150227.428183, \"EndTime\": 1706150227.6382556, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 209.49435234069824, \"count\": 1, \"min\": 209.49435234069824, \"max\": 209.49435234069824}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #progress_metric: host=algo-1, completed 51.64835164835165 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150227.428736, \"EndTime\": 1706150227.6384573, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 46, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3318489.0, \"count\": 1, \"min\": 3318489, \"max\": 3318489}, \"Total Batches Seen\": {\"sum\": 3385.0, \"count\": 1, \"min\": 3385, \"max\": 3385}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 48.0, \"count\": 1, \"min\": 48, \"max\": 48}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=336353.8374599092 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=47, batch=0 train rmse <loss>=0.9110062309921384\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=47, batch=0 train mse <loss>=0.8299323529065015\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=47, batch=0 train absolute_loss <loss>=0.714450705699038\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:07.846] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 96, \"duration\": 206, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=47, train rmse <loss>=0.9971030262178664\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=47, train mse <loss>=0.9942144448928271\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=47, train absolute_loss <loss>=0.7634683656340714\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150227.6383262, \"EndTime\": 1706150227.8474598, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 208.56571197509766, \"count\": 1, \"min\": 208.56571197509766, \"max\": 208.56571197509766}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #progress_metric: host=algo-1, completed 52.747252747252745 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150227.63887, \"EndTime\": 1706150227.8476808, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 47, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3389074.0, \"count\": 1, \"min\": 3389074, \"max\": 3389074}, \"Total Batches Seen\": {\"sum\": 3457.0, \"count\": 1, \"min\": 3457, \"max\": 3457}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 49.0, \"count\": 1, \"min\": 49, \"max\": 49}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=337858.9059967955 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=48, batch=0 train rmse <loss>=0.9093196552501569\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=48, batch=0 train mse <loss>=0.8268622354242643\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:07 INFO 140081874167616] #quality_metric: host=algo-1, epoch=48, batch=0 train absolute_loss <loss>=0.7127667125801685\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:08.060] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 98, \"duration\": 210, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=48, train rmse <loss>=0.9954594761477839\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=48, train mse <loss>=0.9909395686524202\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=48, train absolute_loss <loss>=0.7618799079538537\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150227.847523, \"EndTime\": 1706150228.0607796, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 212.83650398254395, \"count\": 1, \"min\": 212.83650398254395, \"max\": 212.83650398254395}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #progress_metric: host=algo-1, completed 53.84615384615385 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150227.8479197, \"EndTime\": 1706150228.06099, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 48, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3459659.0, \"count\": 1, \"min\": 3459659, \"max\": 3459659}, \"Total Batches Seen\": {\"sum\": 3529.0, \"count\": 1, \"min\": 3529, \"max\": 3529}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 50.0, \"count\": 1, \"min\": 50, \"max\": 50}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=331088.03499935137 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=49, batch=0 train rmse <loss>=0.9076700287999053\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=49, batch=0 train mse <loss>=0.8238648811816209\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=49, batch=0 train absolute_loss <loss>=0.7111002808845259\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:08.261] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 100, \"duration\": 198, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=49, train rmse <loss>=0.9938513591703932\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=49, train mse <loss>=0.987740524124838\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=49, train absolute_loss <loss>=0.7603255556969203\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150228.0608497, \"EndTime\": 1706150228.261878, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 200.61993598937988, \"count\": 1, \"min\": 200.61993598937988, \"max\": 200.61993598937988}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #progress_metric: host=algo-1, completed 54.94505494505494 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150228.061235, \"EndTime\": 1706150228.2620385, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 49, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3530244.0, \"count\": 1, \"min\": 3530244, \"max\": 3530244}, \"Total Batches Seen\": {\"sum\": 3601.0, \"count\": 1, \"min\": 3601, \"max\": 3601}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 51.0, \"count\": 1, \"min\": 51, \"max\": 51}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=351344.2330783791 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=50, batch=0 train rmse <loss>=0.9060566046767693\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=50, batch=0 train mse <loss>=0.8209385708783954\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=50, batch=0 train absolute_loss <loss>=0.709466822910117\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:08.473] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 102, \"duration\": 209, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=50, train rmse <loss>=0.9922778712064845\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=50, train mse <loss>=0.9846153736860725\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=50, train absolute_loss <loss>=0.7588042053045269\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150228.2619345, \"EndTime\": 1706150228.474341, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 212.08596229553223, \"count\": 1, \"min\": 212.08596229553223, \"max\": 212.08596229553223}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #progress_metric: host=algo-1, completed 56.043956043956044 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150228.2622342, \"EndTime\": 1706150228.474487, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 50, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3600829.0, \"count\": 1, \"min\": 3600829, \"max\": 3600829}, \"Total Batches Seen\": {\"sum\": 3673.0, \"count\": 1, \"min\": 3673, \"max\": 3673}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 52.0, \"count\": 1, \"min\": 52, \"max\": 52}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=332418.9181323321 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=51, batch=0 train rmse <loss>=0.904478117015965\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=51, batch=0 train mse <loss>=0.8180806641607458\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=51, batch=0 train absolute_loss <loss>=0.7078842070980571\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:08.692] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 104, \"duration\": 215, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=51, train rmse <loss>=0.9907380805902913\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=51, train mse <loss>=0.9815619443317347\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=51, train absolute_loss <loss>=0.7573165535367151\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150228.474396, \"EndTime\": 1706150228.6926696, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 217.7712917327881, \"count\": 1, \"min\": 217.7712917327881, \"max\": 217.7712917327881}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #progress_metric: host=algo-1, completed 57.142857142857146 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150228.474874, \"EndTime\": 1706150228.6929092, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 51, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3671414.0, \"count\": 1, \"min\": 3671414, \"max\": 3671414}, \"Total Batches Seen\": {\"sum\": 3745.0, \"count\": 1, \"min\": 3745, \"max\": 3745}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 53.0, \"count\": 1, \"min\": 53, \"max\": 53}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=323552.7231197808 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=52, batch=0 train rmse <loss>=0.9029337289753554\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=52, batch=0 train mse <loss>=0.8152893189213405\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=52, batch=0 train absolute_loss <loss>=0.7063322930748553\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:08.913] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 106, \"duration\": 218, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=52, train rmse <loss>=0.9892310334156583\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=52, train mse <loss>=0.9785780374726113\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=52, train absolute_loss <loss>=0.7558632988591816\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150228.6927562, \"EndTime\": 1706150228.913691, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 220.28756141662598, \"count\": 1, \"min\": 220.28756141662598, \"max\": 220.28756141662598}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #progress_metric: host=algo-1, completed 58.24175824175824 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150228.6933796, \"EndTime\": 1706150228.9138865, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 52, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3741999.0, \"count\": 1, \"min\": 3741999, \"max\": 3741999}, \"Total Batches Seen\": {\"sum\": 3817.0, \"count\": 1, \"min\": 3817, \"max\": 3817}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 54.0, \"count\": 1, \"min\": 54, \"max\": 54}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=319893.40433072567 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=53, batch=0 train rmse <loss>=0.9014225940439081\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=53, batch=0 train mse <loss>=0.8125626930528483\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:08 INFO 140081874167616] #quality_metric: host=algo-1, epoch=53, batch=0 train absolute_loss <loss>=0.7048219492737676\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:09.118] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 108, \"duration\": 201, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=53, train rmse <loss>=0.98775587801287\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=53, train mse <loss>=0.9756616745489757\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=53, train absolute_loss <loss>=0.7544428302808387\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150228.9137554, \"EndTime\": 1706150229.1184843, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 204.15043830871582, \"count\": 1, \"min\": 204.15043830871582, \"max\": 204.15043830871582}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #progress_metric: host=algo-1, completed 59.34065934065934 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150228.9143114, \"EndTime\": 1706150229.1187048, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 53, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3812584.0, \"count\": 1, \"min\": 3812584, \"max\": 3812584}, \"Total Batches Seen\": {\"sum\": 3889.0, \"count\": 1, \"min\": 3889, \"max\": 3889}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 55.0, \"count\": 1, \"min\": 55, \"max\": 55}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=345164.2231865336 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=54, batch=0 train rmse <loss>=0.8999436174688354\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=54, batch=0 train mse <loss>=0.8098985146228936\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=54, batch=0 train absolute_loss <loss>=0.7033582107881665\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:09.327] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 110, \"duration\": 207, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=54, train rmse <loss>=0.9863116740539942\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=54, train mse <loss>=0.9728107183751925\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=54, train absolute_loss <loss>=0.7530549345948193\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150229.1185503, \"EndTime\": 1706150229.3282962, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 209.2127799987793, \"count\": 1, \"min\": 209.2127799987793, \"max\": 209.2127799987793}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #progress_metric: host=algo-1, completed 60.43956043956044 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150229.1190636, \"EndTime\": 1706150229.3284464, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 54, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3883169.0, \"count\": 1, \"min\": 3883169, \"max\": 3883169}, \"Total Batches Seen\": {\"sum\": 3961.0, \"count\": 1, \"min\": 3961, \"max\": 3961}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 56.0, \"count\": 1, \"min\": 56, \"max\": 56}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=336970.9744734952 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=55, batch=0 train rmse <loss>=0.8984961379692242\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=55, batch=0 train mse <loss>=0.8072953099456112\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=55, batch=0 train absolute_loss <loss>=0.701944761832715\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:09.535] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 112, \"duration\": 204, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=55, train rmse <loss>=0.9848976783700294\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=55, train mse <loss>=0.9700234368586738\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=55, train absolute_loss <loss>=0.7516997832194448\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150229.3283527, \"EndTime\": 1706150229.5361352, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 207.28135108947754, \"count\": 1, \"min\": 207.28135108947754, \"max\": 207.28135108947754}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #progress_metric: host=algo-1, completed 61.53846153846154 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150229.3288333, \"EndTime\": 1706150229.5362825, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 55, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3953754.0, \"count\": 1, \"min\": 3953754, \"max\": 3953754}, \"Total Batches Seen\": {\"sum\": 4033.0, \"count\": 1, \"min\": 4033, \"max\": 4033}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 57.0, \"count\": 1, \"min\": 57, \"max\": 57}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=340109.30628281273 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=56, batch=0 train rmse <loss>=0.8970790417174094\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=56, batch=0 train mse <loss>=0.8047508070886255\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=56, batch=0 train absolute_loss <loss>=0.7005633041412538\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:09.752] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 114, \"duration\": 213, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=56, train rmse <loss>=0.9835130231931793\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=56, train mse <loss>=0.9672978667905873\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=56, train absolute_loss <loss>=0.7503731930359828\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150229.5361917, \"EndTime\": 1706150229.752608, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 215.93713760375977, \"count\": 1, \"min\": 215.93713760375977, \"max\": 215.93713760375977}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #progress_metric: host=algo-1, completed 62.637362637362635 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150229.5366514, \"EndTime\": 1706150229.7528527, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 56, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4024339.0, \"count\": 1, \"min\": 4024339, \"max\": 4024339}, \"Total Batches Seen\": {\"sum\": 4105.0, \"count\": 1, \"min\": 4105, \"max\": 4105}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 58.0, \"count\": 1, \"min\": 58, \"max\": 58}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=326298.9443983988 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=57, batch=0 train rmse <loss>=0.8956915817171198\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=57, batch=0 train mse <loss>=0.802263409558916\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=57, batch=0 train absolute_loss <loss>=0.6992379079162475\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:09.970] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 116, \"duration\": 215, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=57, train rmse <loss>=0.9821568231942746\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=57, train mse <loss>=0.9646320253470694\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=57, train absolute_loss <loss>=0.7490748774944044\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150229.7526681, \"EndTime\": 1706150229.9708366, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 217.56744384765625, \"count\": 1, \"min\": 217.56744384765625, \"max\": 217.56744384765625}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #progress_metric: host=algo-1, completed 63.73626373626374 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150229.7532482, \"EndTime\": 1706150229.9709866, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 57, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4094924.0, \"count\": 1, \"min\": 4094924, \"max\": 4094924}, \"Total Batches Seen\": {\"sum\": 4177.0, \"count\": 1, \"min\": 4177, \"max\": 4177}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 59.0, \"count\": 1, \"min\": 59, \"max\": 59}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=324049.59210166265 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=58, batch=0 train rmse <loss>=0.8943329690109184\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=58, batch=0 train mse <loss>=0.7998314594598843\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:09 INFO 140081874167616] #quality_metric: host=algo-1, epoch=58, batch=0 train absolute_loss <loss>=0.6979492310307155\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:10.180] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 118, \"duration\": 207, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=58, train rmse <loss>=0.980828357344498\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=58, train mse <loss>=0.9620242665711063\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=58, train absolute_loss <loss>=0.7478041748005939\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150229.970894, \"EndTime\": 1706150230.1812544, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 209.92183685302734, \"count\": 1, \"min\": 209.92183685302734, \"max\": 209.92183685302734}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #progress_metric: host=algo-1, completed 64.83516483516483 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150229.9713097, \"EndTime\": 1706150230.1814845, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 58, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4165509.0, \"count\": 1, \"min\": 4165509, \"max\": 4165509}, \"Total Batches Seen\": {\"sum\": 4249.0, \"count\": 1, \"min\": 4249, \"max\": 4249}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 60.0, \"count\": 1, \"min\": 60, \"max\": 60}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=335652.93107807357 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=59, batch=0 train rmse <loss>=0.8930022694711482\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=59, batch=0 train mse <loss>=0.7974530532806212\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=59, batch=0 train absolute_loss <loss>=0.6966827822403169\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:10.394] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 120, \"duration\": 211, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=59, train rmse <loss>=0.9795268099351381\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=59, train mse <loss>=0.9594727713817082\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=59, train absolute_loss <loss>=0.7465603438474816\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150230.181325, \"EndTime\": 1706150230.3952448, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 213.3352756500244, \"count\": 1, \"min\": 213.3352756500244, \"max\": 213.3352756500244}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #progress_metric: host=algo-1, completed 65.93406593406593 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150230.181886, \"EndTime\": 1706150230.39546, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 59, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4236094.0, \"count\": 1, \"min\": 4236094, \"max\": 4236094}, \"Total Batches Seen\": {\"sum\": 4321.0, \"count\": 1, \"min\": 4321, \"max\": 4321}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 61.0, \"count\": 1, \"min\": 61, \"max\": 61}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=330323.3531416177 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=60, batch=0 train rmse <loss>=0.8916988161587068\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=60, batch=0 train mse <loss>=0.7951267787388393\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=60, batch=0 train absolute_loss <loss>=0.695444947517134\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:10.596] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 122, \"duration\": 198, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=60, train rmse <loss>=0.9782514475709652\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=60, train mse <loss>=0.9569758946746888\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=60, train absolute_loss <loss>=0.7453422537858444\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150230.3953097, \"EndTime\": 1706150230.5967784, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 201.0643482208252, \"count\": 1, \"min\": 201.0643482208252, \"max\": 201.0643482208252}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #progress_metric: host=algo-1, completed 67.03296703296704 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150230.395691, \"EndTime\": 1706150230.5970123, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 60, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4306679.0, \"count\": 1, \"min\": 4306679, \"max\": 4306679}, \"Total Batches Seen\": {\"sum\": 4393.0, \"count\": 1, \"min\": 4393, \"max\": 4393}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 62.0, \"count\": 1, \"min\": 62, \"max\": 62}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=350415.62449992186 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=61, batch=0 train rmse <loss>=0.8904218322466706\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=61, batch=0 train mse <loss>=0.7928510393415179\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=61, batch=0 train absolute_loss <loss>=0.6942276215889085\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:10.849] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 124, \"duration\": 250, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=61, train rmse <loss>=0.9770015300091431\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=61, train mse <loss>=0.9545319896402067\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=61, train absolute_loss <loss>=0.7441487004232972\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150230.5968494, \"EndTime\": 1706150230.8500762, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 252.80451774597168, \"count\": 1, \"min\": 252.80451774597168, \"max\": 252.80451774597168}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #progress_metric: host=algo-1, completed 68.13186813186813 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150230.5972455, \"EndTime\": 1706150230.850277, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 61, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4377264.0, \"count\": 1, \"min\": 4377264, \"max\": 4377264}, \"Total Batches Seen\": {\"sum\": 4465.0, \"count\": 1, \"min\": 4465, \"max\": 4465}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 63.0, \"count\": 1, \"min\": 63, \"max\": 63}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=278842.81725905056 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=62, batch=0 train rmse <loss>=0.8891704649775998\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=62, batch=0 train mse <loss>=0.7906241157884809\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:10 INFO 140081874167616] #quality_metric: host=algo-1, epoch=62, batch=0 train absolute_loss <loss>=0.6930326465629716\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:11.069] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 126, \"duration\": 217, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=62, train rmse <loss>=0.975776249130363\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=62, train mse <loss>=0.9521392883669203\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=62, train absolute_loss <loss>=0.7429800223323447\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150230.8501337, \"EndTime\": 1706150231.0701857, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 219.6822166442871, \"count\": 1, \"min\": 219.6822166442871, \"max\": 219.6822166442871}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #progress_metric: host=algo-1, completed 69.23076923076923 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150230.8504798, \"EndTime\": 1706150231.070372, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 62, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4447849.0, \"count\": 1, \"min\": 4447849, \"max\": 4447849}, \"Total Batches Seen\": {\"sum\": 4537.0, \"count\": 1, \"min\": 4537, \"max\": 4537}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 64.0, \"count\": 1, \"min\": 64, \"max\": 64}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=320835.6519232478 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=63, batch=0 train rmse <loss>=0.8879441311299794\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=63, batch=0 train mse <loss>=0.7884447800081741\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=63, batch=0 train absolute_loss <loss>=0.6918587943677691\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:11.271] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 128, \"duration\": 199, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=63, train rmse <loss>=0.9745750161735288\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=63, train mse <loss>=0.9497964621496339\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=63, train absolute_loss <loss>=0.7418348285513865\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150231.0702403, \"EndTime\": 1706150231.2721772, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 201.3833522796631, \"count\": 1, \"min\": 201.3833522796631, \"max\": 201.3833522796631}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #progress_metric: host=algo-1, completed 70.32967032967034 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150231.0707676, \"EndTime\": 1706150231.2724023, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 63, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4518434.0, \"count\": 1, \"min\": 4518434, \"max\": 4518434}, \"Total Batches Seen\": {\"sum\": 4609.0, \"count\": 1, \"min\": 4609, \"max\": 4609}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 65.0, \"count\": 1, \"min\": 65, \"max\": 65}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=349860.3156430622 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=64, batch=0 train rmse <loss>=0.886741999740623\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=64, batch=0 train mse <loss>=0.786311374103999\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=64, batch=0 train absolute_loss <loss>=0.690713433432627\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:11.473] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 130, \"duration\": 199, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=64, train rmse <loss>=0.9733971062392325\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=64, train mse <loss>=0.9475019264349116\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=64, train absolute_loss <loss>=0.7407128393530126\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150231.2722452, \"EndTime\": 1706150231.473858, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 201.05338096618652, \"count\": 1, \"min\": 201.05338096618652, \"max\": 201.05338096618652}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #progress_metric: host=algo-1, completed 71.42857142857143 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150231.2727811, \"EndTime\": 1706150231.4740531, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 64, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4589019.0, \"count\": 1, \"min\": 4589019, \"max\": 4589019}, \"Total Batches Seen\": {\"sum\": 4681.0, \"count\": 1, \"min\": 4681, \"max\": 4681}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=350518.51464563946 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=65, batch=0 train rmse <loss>=0.8855634066498265\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=65, batch=0 train mse <loss>=0.7842225471972459\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=65, batch=0 train absolute_loss <loss>=0.6895988970934985\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:11.678] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 132, \"duration\": 202, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=65, train rmse <loss>=0.9722418602525644\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=65, train mse <loss>=0.945254234827367\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=65, train absolute_loss <loss>=0.7396128462807007\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150231.4739213, \"EndTime\": 1706150231.6792705, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 204.85281944274902, \"count\": 1, \"min\": 204.85281944274902, \"max\": 204.85281944274902}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #progress_metric: host=algo-1, completed 72.52747252747253 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150231.4743953, \"EndTime\": 1706150231.6794546, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 65, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4659604.0, \"count\": 1, \"min\": 4659604, \"max\": 4659604}, \"Total Batches Seen\": {\"sum\": 4753.0, \"count\": 1, \"min\": 4753, \"max\": 4753}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 67.0, \"count\": 1, \"min\": 67, \"max\": 67}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=344049.9103312028 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=66, batch=0 train rmse <loss>=0.8844076475277831\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=66, batch=0 train mse <loss>=0.7821768870056275\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=66, batch=0 train absolute_loss <loss>=0.688512483592964\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:11.901] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 134, \"duration\": 219, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=66, train rmse <loss>=0.9711085862820161\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=66, train mse <loss>=0.9430518863506561\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=66, train absolute_loss <loss>=0.7385351768201985\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150231.6793318, \"EndTime\": 1706150231.901497, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 221.6627597808838, \"count\": 1, \"min\": 221.6627597808838, \"max\": 221.6627597808838}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #progress_metric: host=algo-1, completed 73.62637362637362 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150231.679809, \"EndTime\": 1706150231.9017203, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 66, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4730189.0, \"count\": 1, \"min\": 4730189, \"max\": 4730189}, \"Total Batches Seen\": {\"sum\": 4825.0, \"count\": 1, \"min\": 4825, \"max\": 4825}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 68.0, \"count\": 1, \"min\": 68, \"max\": 68}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=317928.76478604466 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=67, batch=0 train rmse <loss>=0.8832742558638852\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=67, batch=0 train mse <loss>=0.7801734110719002\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:11 INFO 140081874167616] #quality_metric: host=algo-1, epoch=67, batch=0 train absolute_loss <loss>=0.6874364472970637\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:12.104] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 136, \"duration\": 200, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=67, train rmse <loss>=0.9699967001759678\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=67, train mse <loss>=0.9408935983522664\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=67, train absolute_loss <loss>=0.7374775940050569\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150231.9015663, \"EndTime\": 1706150232.1050766, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 202.9428482055664, \"count\": 1, \"min\": 202.9428482055664, \"max\": 202.9428482055664}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #progress_metric: host=algo-1, completed 74.72527472527473 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150231.9021094, \"EndTime\": 1706150232.1053035, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 67, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4800774.0, \"count\": 1, \"min\": 4800774, \"max\": 4800774}, \"Total Batches Seen\": {\"sum\": 4897.0, \"count\": 1, \"min\": 4897, \"max\": 4897}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 69.0, \"count\": 1, \"min\": 69, \"max\": 69}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=347179.16260917694 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=68, batch=0 train rmse <loss>=0.8821623781931904\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=68, batch=0 train mse <loss>=0.7782104614994655\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=68, batch=0 train absolute_loss <loss>=0.6863711566272636\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:12.322] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 138, \"duration\": 215, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=68, train rmse <loss>=0.9689056167395657\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=68, train mse <loss>=0.938778094149478\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=68, train absolute_loss <loss>=0.7364414580950874\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150232.1051471, \"EndTime\": 1706150232.3233075, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 217.58580207824707, \"count\": 1, \"min\": 217.58580207824707, \"max\": 217.58580207824707}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #progress_metric: host=algo-1, completed 75.82417582417582 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150232.105701, \"EndTime\": 1706150232.3234987, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 68, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4871359.0, \"count\": 1, \"min\": 4871359, \"max\": 4871359}, \"Total Batches Seen\": {\"sum\": 4969.0, \"count\": 1, \"min\": 4969, \"max\": 4969}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 70.0, \"count\": 1, \"min\": 70, \"max\": 70}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=323953.8537225894 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=69, batch=0 train rmse <loss>=0.8810715732757799\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=69, batch=0 train mse <loss>=0.7762871172346579\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=69, batch=0 train absolute_loss <loss>=0.6853218308876697\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:12.531] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 140, \"duration\": 205, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=69, train rmse <loss>=0.96783474589101\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=69, train mse <loss>=0.9367040953539161\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=69, train absolute_loss <loss>=0.7354285199450828\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150232.3233972, \"EndTime\": 1706150232.5316663, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 207.79037475585938, \"count\": 1, \"min\": 207.79037475585938, \"max\": 207.79037475585938}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #progress_metric: host=algo-1, completed 76.92307692307692 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150232.323852, \"EndTime\": 1706150232.5318544, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 69, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4941944.0, \"count\": 1, \"min\": 4941944, \"max\": 4941944}, \"Total Batches Seen\": {\"sum\": 5041.0, \"count\": 1, \"min\": 5041, \"max\": 5041}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=339172.6043392288 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=70, batch=0 train rmse <loss>=0.8800012565954101\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=70, batch=0 train mse <loss>=0.7744022116095007\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=70, batch=0 train absolute_loss <loss>=0.684291110432124\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:12.748] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 142, \"duration\": 214, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=70, train rmse <loss>=0.9667834579150496\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=70, train mse <loss>=0.9346702544981805\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=70, train absolute_loss <loss>=0.7344346331078921\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150232.531724, \"EndTime\": 1706150232.7490296, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 216.79258346557617, \"count\": 1, \"min\": 216.79258346557617, \"max\": 216.79258346557617}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #progress_metric: host=algo-1, completed 78.02197802197803 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150232.532217, \"EndTime\": 1706150232.7491915, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 70, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5012529.0, \"count\": 1, \"min\": 5012529, \"max\": 5012529}, \"Total Batches Seen\": {\"sum\": 5113.0, \"count\": 1, \"min\": 5113, \"max\": 5113}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=325185.02212165814 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=71, batch=0 train rmse <loss>=0.8789506646781313\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=71, batch=0 train mse <loss>=0.7725542709381288\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=71, batch=0 train absolute_loss <loss>=0.6832791794713594\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:12.963] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 144, \"duration\": 212, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=71, train rmse <loss>=0.96575126042872\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=71, train mse <loss>=0.9326754970196613\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=71, train absolute_loss <loss>=0.73345819597353\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150232.749088, \"EndTime\": 1706150232.9640992, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 214.53022956848145, \"count\": 1, \"min\": 214.53022956848145, \"max\": 214.53022956848145}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #progress_metric: host=algo-1, completed 79.12087912087912 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150232.7495434, \"EndTime\": 1706150232.9642766, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 71, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5083114.0, \"count\": 1, \"min\": 5083114, \"max\": 5083114}, \"Total Batches Seen\": {\"sum\": 5185.0, \"count\": 1, \"min\": 5185, \"max\": 5185}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 73.0, \"count\": 1, \"min\": 73, \"max\": 73}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=328555.3106102559 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=72, batch=0 train rmse <loss>=0.8779194137129169\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=72, batch=0 train mse <loss>=0.7707424969740317\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:12 INFO 140081874167616] #quality_metric: host=algo-1, epoch=72, batch=0 train absolute_loss <loss>=0.6822839502837337\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:13.168] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 146, \"duration\": 202, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=72, train rmse <loss>=0.9647375707148226\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=72, train mse <loss>=0.9307185803487373\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=72, train absolute_loss <loss>=0.7325000588109822\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150232.9641562, \"EndTime\": 1706150233.1697896, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 205.11341094970703, \"count\": 1, \"min\": 205.11341094970703, \"max\": 205.11341094970703}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #progress_metric: host=algo-1, completed 80.21978021978022 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150232.9646513, \"EndTime\": 1706150233.1699991, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 72, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5153699.0, \"count\": 1, \"min\": 5153699, \"max\": 5153699}, \"Total Batches Seen\": {\"sum\": 5257.0, \"count\": 1, \"min\": 5257, \"max\": 5257}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 74.0, \"count\": 1, \"min\": 74, \"max\": 74}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=343558.8268251076 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=73, batch=0 train rmse <loss>=0.876906976740628\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=73, batch=0 train mse <loss>=0.7689658458563883\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=73, batch=0 train absolute_loss <loss>=0.6813035807619152\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:13.371] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 148, \"duration\": 199, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=73, train rmse <loss>=0.9637419095899247\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=73, train mse <loss>=0.9287984683000345\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=73, train absolute_loss <loss>=0.7315592280762483\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150233.1698647, \"EndTime\": 1706150233.3717394, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 201.30324363708496, \"count\": 1, \"min\": 201.30324363708496, \"max\": 201.30324363708496}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #progress_metric: host=algo-1, completed 81.31868131868131 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150233.1704125, \"EndTime\": 1706150233.371924, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 73, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5224284.0, \"count\": 1, \"min\": 5224284, \"max\": 5224284}, \"Total Batches Seen\": {\"sum\": 5329.0, \"count\": 1, \"min\": 5329, \"max\": 5329}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=350122.2218227575 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=74, batch=0 train rmse <loss>=0.8759126478744835\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=74, batch=0 train mse <loss>=0.7672229667064889\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=74, batch=0 train absolute_loss <loss>=0.6803386849416814\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:13.585] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 150, \"duration\": 211, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=74, train rmse <loss>=0.9627638001722482\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=74, train mse <loss>=0.9269141349221086\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=74, train absolute_loss <loss>=0.7306353396119992\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150233.3717995, \"EndTime\": 1706150233.5865982, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 214.28489685058594, \"count\": 1, \"min\": 214.28489685058594, \"max\": 214.28489685058594}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #progress_metric: host=algo-1, completed 82.41758241758242 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150233.3722928, \"EndTime\": 1706150233.586744, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 74, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5294869.0, \"count\": 1, \"min\": 5294869, \"max\": 5294869}, \"Total Batches Seen\": {\"sum\": 5401.0, \"count\": 1, \"min\": 5401, \"max\": 5401}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 76.0, \"count\": 1, \"min\": 76, \"max\": 76}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=329011.7231346775 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=75, batch=0 train rmse <loss>=0.8749361379486827\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=75, batch=0 train mse <loss>=0.7655132454885564\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=75, batch=0 train absolute_loss <loss>=0.6793938066877829\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:13.806] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 152, \"duration\": 217, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=75, train rmse <loss>=0.9618026398540952\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=75, train mse <loss>=0.9250643180303064\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=75, train absolute_loss <loss>=0.7297279891780152\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150233.5866525, \"EndTime\": 1706150233.8066347, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 219.5281982421875, \"count\": 1, \"min\": 219.5281982421875, \"max\": 219.5281982421875}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #progress_metric: host=algo-1, completed 83.51648351648352 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150233.5870824, \"EndTime\": 1706150233.8068416, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 75, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5365454.0, \"count\": 1, \"min\": 5365454, \"max\": 5365454}, \"Total Batches Seen\": {\"sum\": 5473.0, \"count\": 1, \"min\": 5473, \"max\": 5473}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 77.0, \"count\": 1, \"min\": 77, \"max\": 77}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=321027.69200073736 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=76, batch=0 train rmse <loss>=0.8739768392438176\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=76, batch=0 train mse <loss>=0.7638355155346139\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:13 INFO 140081874167616] #quality_metric: host=algo-1, epoch=76, batch=0 train absolute_loss <loss>=0.6784598582707181\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:14.019] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 154, \"duration\": 210, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=76, train rmse <loss>=0.960858118702182\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=76, train mse <loss>=0.9232483242758963\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=76, train absolute_loss <loss>=0.7288372791135922\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150233.8067033, \"EndTime\": 1706150234.0204544, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 213.1955623626709, \"count\": 1, \"min\": 213.1955623626709, \"max\": 213.1955623626709}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #progress_metric: host=algo-1, completed 84.61538461538461 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150233.8072364, \"EndTime\": 1706150234.0206578, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 76, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5436039.0, \"count\": 1, \"min\": 5436039, \"max\": 5436039}, \"Total Batches Seen\": {\"sum\": 5545.0, \"count\": 1, \"min\": 5545, \"max\": 5545}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 78.0, \"count\": 1, \"min\": 78, \"max\": 78}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=330541.6838866274 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=77, batch=0 train rmse <loss>=0.8730344216612005\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=77, batch=0 train mse <loss>=0.7621891014053068\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=77, batch=0 train absolute_loss <loss>=0.6775346291616888\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:14.226] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 156, \"duration\": 204, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=77, train rmse <loss>=0.9599297008037112\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=77, train mse <loss>=0.9214650304851024\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=77, train absolute_loss <loss>=0.7279626670204604\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150234.0205202, \"EndTime\": 1706150234.22726, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 206.19702339172363, \"count\": 1, \"min\": 206.19702339172363, \"max\": 206.19702339172363}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #progress_metric: host=algo-1, completed 85.71428571428571 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150234.0210412, \"EndTime\": 1706150234.2274334, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 77, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5506624.0, \"count\": 1, \"min\": 5506624, \"max\": 5506624}, \"Total Batches Seen\": {\"sum\": 5617.0, \"count\": 1, \"min\": 5617, \"max\": 5617}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 79.0, \"count\": 1, \"min\": 79, \"max\": 79}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=341817.8654896152 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=78, batch=0 train rmse <loss>=0.8721082358452308\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=78, batch=0 train mse <loss>=0.7605727750290807\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=78, batch=0 train absolute_loss <loss>=0.6766277597223969\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:14.441] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 158, \"duration\": 212, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=78, train rmse <loss>=0.9590169082563208\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=78, train mse <loss>=0.9197134303215124\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=78, train absolute_loss <loss>=0.7271050986842823\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150234.2273185, \"EndTime\": 1706150234.4424908, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 214.7982120513916, \"count\": 1, \"min\": 214.7982120513916, \"max\": 214.7982120513916}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #progress_metric: host=algo-1, completed 86.81318681318682 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150234.227666, \"EndTime\": 1706150234.4427183, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 78, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5577209.0, \"count\": 1, \"min\": 5577209, \"max\": 5577209}, \"Total Batches Seen\": {\"sum\": 5689.0, \"count\": 1, \"min\": 5689, \"max\": 5689}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 80.0, \"count\": 1, \"min\": 80, \"max\": 80}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=328017.2795795067 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=79, batch=0 train rmse <loss>=0.8711979811559245\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=79, batch=0 train mse <loss>=0.7589859223701585\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=79, batch=0 train absolute_loss <loss>=0.6757339078415807\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:14.655] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 160, \"duration\": 211, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=79, train rmse <loss>=0.9581194319015186\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=79, train mse <loss>=0.9179928457872888\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=79, train absolute_loss <loss>=0.726263831292333\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150234.442559, \"EndTime\": 1706150234.6562839, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 213.29021453857422, \"count\": 1, \"min\": 213.29021453857422, \"max\": 213.29021453857422}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #progress_metric: host=algo-1, completed 87.91208791208791 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150234.4429693, \"EndTime\": 1706150234.6564374, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 79, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5647794.0, \"count\": 1, \"min\": 5647794, \"max\": 5647794}, \"Total Batches Seen\": {\"sum\": 5761.0, \"count\": 1, \"min\": 5761, \"max\": 5761}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 81.0, \"count\": 1, \"min\": 81, \"max\": 81}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=330516.22169503255 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=80, batch=0 train rmse <loss>=0.8703030725926119\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=80, batch=0 train mse <loss>=0.757427438164141\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=80, batch=0 train absolute_loss <loss>=0.6748586612448126\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:14.878] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 162, \"duration\": 220, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=80, train rmse <loss>=0.9572367936275192\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=80, train mse <loss>=0.9163022790742938\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=80, train absolute_loss <loss>=0.7254384375780508\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150234.6563435, \"EndTime\": 1706150234.8793983, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 222.77355194091797, \"count\": 1, \"min\": 222.77355194091797, \"max\": 222.77355194091797}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #progress_metric: host=algo-1, completed 89.01098901098901 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150234.6566021, \"EndTime\": 1706150234.8796287, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 80, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5718379.0, \"count\": 1, \"min\": 5718379, \"max\": 5718379}, \"Total Batches Seen\": {\"sum\": 5833.0, \"count\": 1, \"min\": 5833, \"max\": 5833}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 82.0, \"count\": 1, \"min\": 82, \"max\": 82}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=316316.94614207686 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=81, batch=0 train rmse <loss>=0.8694232397278263\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=81, batch=0 train mse <loss>=0.7558967697788292\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:14 INFO 140081874167616] #quality_metric: host=algo-1, epoch=81, batch=0 train absolute_loss <loss>=0.673991519920303\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:15.091] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 164, \"duration\": 209, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=81, train rmse <loss>=0.956368594445581\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=81, train mse <loss>=0.9146408884418162\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=81, train absolute_loss <loss>=0.7246270182946638\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150234.8794706, \"EndTime\": 1706150235.0920475, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 211.94148063659668, \"count\": 1, \"min\": 211.94148063659668, \"max\": 211.94148063659668}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #progress_metric: host=algo-1, completed 90.10989010989012 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150234.880082, \"EndTime\": 1706150235.0922542, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 81, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5788964.0, \"count\": 1, \"min\": 5788964, \"max\": 5788964}, \"Total Batches Seen\": {\"sum\": 5905.0, \"count\": 1, \"min\": 5905, \"max\": 5905}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 83.0, \"count\": 1, \"min\": 83, \"max\": 83}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=332519.35256121546 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=82, batch=0 train rmse <loss>=0.8685580335038844\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=82, batch=0 train mse <loss>=0.7543930575641348\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=82, batch=0 train absolute_loss <loss>=0.6731355540469379\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:15.291] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 166, \"duration\": 197, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=82, train rmse <loss>=0.9555144180769911\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=82, train mse <loss>=0.913007803153011\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=82, train absolute_loss <loss>=0.7238300390859698\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150235.0921152, \"EndTime\": 1706150235.2922697, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 199.615478515625, \"count\": 1, \"min\": 199.615478515625, \"max\": 199.615478515625}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #progress_metric: host=algo-1, completed 91.20879120879121 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150235.0926316, \"EndTime\": 1706150235.2924829, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 82, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5859549.0, \"count\": 1, \"min\": 5859549, \"max\": 5859549}, \"Total Batches Seen\": {\"sum\": 5977.0, \"count\": 1, \"min\": 5977, \"max\": 5977}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 84.0, \"count\": 1, \"min\": 84, \"max\": 84}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=352985.50982035656 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=83, batch=0 train rmse <loss>=0.8677071792303314\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=83, batch=0 train mse <loss>=0.7529157488878584\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=83, batch=0 train absolute_loss <loss>=0.6722992373184419\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:15.494] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 168, \"duration\": 199, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=83, train rmse <loss>=0.954674018533256\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=83, train mse <loss>=0.9114024816624355\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=83, train absolute_loss <loss>=0.7230482436175211\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150235.2923396, \"EndTime\": 1706150235.495147, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 202.22043991088867, \"count\": 1, \"min\": 202.22043991088867, \"max\": 202.22043991088867}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #progress_metric: host=algo-1, completed 92.3076923076923 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150235.2929025, \"EndTime\": 1706150235.4953806, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 83, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5930134.0, \"count\": 1, \"min\": 5930134, \"max\": 5930134}, \"Total Batches Seen\": {\"sum\": 6049.0, \"count\": 1, \"min\": 6049, \"max\": 6049}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 85.0, \"count\": 1, \"min\": 85, \"max\": 85}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=348404.86998437176 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=84, batch=0 train rmse <loss>=0.8668700816648369\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=84, batch=0 train mse <loss>=0.7514637384856011\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=84, batch=0 train absolute_loss <loss>=0.6714772890271316\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:15.694] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 170, \"duration\": 197, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=84, train rmse <loss>=0.9538469243846657\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=84, train mse <loss>=0.9098239551580861\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=84, train absolute_loss <loss>=0.7222800055473356\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150235.4952157, \"EndTime\": 1706150235.6948926, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 199.23710823059082, \"count\": 1, \"min\": 199.23710823059082, \"max\": 199.23710823059082}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #progress_metric: host=algo-1, completed 93.4065934065934 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150235.4956295, \"EndTime\": 1706150235.695101, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 84, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6000719.0, \"count\": 1, \"min\": 6000719, \"max\": 6000719}, \"Total Batches Seen\": {\"sum\": 6121.0, \"count\": 1, \"min\": 6121, \"max\": 6121}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 86.0, \"count\": 1, \"min\": 86, \"max\": 86}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=353653.41927746247 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=85, batch=0 train rmse <loss>=0.8660464970939732\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=85, batch=0 train mse <loss>=0.7500365351287412\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=85, batch=0 train absolute_loss <loss>=0.6706688495229187\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:15.909] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 172, \"duration\": 212, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=85, train rmse <loss>=0.9530328320170279\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=85, train mse <loss>=0.9082715789023966\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=85, train absolute_loss <loss>=0.7215251679551593\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150235.6949563, \"EndTime\": 1706150235.9098113, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 214.47420120239258, \"count\": 1, \"min\": 214.47420120239258, \"max\": 214.47420120239258}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #progress_metric: host=algo-1, completed 94.50549450549451 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150235.695313, \"EndTime\": 1706150235.909999, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 85, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6071304.0, \"count\": 1, \"min\": 6071304, \"max\": 6071304}, \"Total Batches Seen\": {\"sum\": 6193.0, \"count\": 1, \"min\": 6193, \"max\": 6193}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 87.0, \"count\": 1, \"min\": 87, \"max\": 87}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=328627.15714786807 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=86, batch=0 train rmse <loss>=0.865236109268159\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=86, batch=0 train mse <loss>=0.7486335247815015\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:15 INFO 140081874167616] #quality_metric: host=algo-1, epoch=86, batch=0 train absolute_loss <loss>=0.6698693135374748\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:16.119] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 174, \"duration\": 207, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=86, train rmse <loss>=0.9522314366847108\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=86, train mse <loss>=0.9067447090106284\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=86, train absolute_loss <loss>=0.720782943681239\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150235.909879, \"EndTime\": 1706150236.120259, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 210.04343032836914, \"count\": 1, \"min\": 210.04343032836914, \"max\": 210.04343032836914}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #progress_metric: host=algo-1, completed 95.6043956043956 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150235.9101918, \"EndTime\": 1706150236.1204538, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 86, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6141889.0, \"count\": 1, \"min\": 6141889, \"max\": 6141889}, \"Total Batches Seen\": {\"sum\": 6265.0, \"count\": 1, \"min\": 6265, \"max\": 6265}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 88.0, \"count\": 1, \"min\": 88, \"max\": 88}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=335525.87641566206 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=87, batch=0 train rmse <loss>=0.8644386001377454\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=87, batch=0 train mse <loss>=0.7472540934081049\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=87, batch=0 train absolute_loss <loss>=0.6690786810707998\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:16.333] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 176, \"duration\": 211, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=87, train rmse <loss>=0.9514423662168956\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=87, train mse <loss>=0.9052425762324052\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=87, train absolute_loss <loss>=0.7200529071646677\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150236.1203275, \"EndTime\": 1706150236.3339286, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 213.01555633544922, \"count\": 1, \"min\": 213.01555633544922, \"max\": 213.01555633544922}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #progress_metric: host=algo-1, completed 96.7032967032967 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150236.1208916, \"EndTime\": 1706150236.3340771, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 87, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6212474.0, \"count\": 1, \"min\": 6212474, \"max\": 6212474}, \"Total Batches Seen\": {\"sum\": 6337.0, \"count\": 1, \"min\": 6337, \"max\": 6337}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 89.0, \"count\": 1, \"min\": 89, \"max\": 89}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=330959.97227606777 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=88, batch=0 train rmse <loss>=0.8636534721489202\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=88, batch=0 train mse <loss>=0.7458973199548856\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=88, batch=0 train absolute_loss <loss>=0.6683103995064135\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:16.544] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 178, \"duration\": 207, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=88, train rmse <loss>=0.9506653494341955\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=88, train mse <loss>=0.9037646066148409\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=88, train absolute_loss <loss>=0.7193353398385103\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150236.3339849, \"EndTime\": 1706150236.5445406, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 210.09373664855957, \"count\": 1, \"min\": 210.09373664855957, \"max\": 210.09373664855957}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #progress_metric: host=algo-1, completed 97.8021978021978 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150236.3344169, \"EndTime\": 1706150236.5449002, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 88, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6283059.0, \"count\": 1, \"min\": 6283059, \"max\": 6283059}, \"Total Batches Seen\": {\"sum\": 6409.0, \"count\": 1, \"min\": 6409, \"max\": 6409}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 90.0, \"count\": 1, \"min\": 90, \"max\": 90}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=335193.47925129865 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=89, batch=0 train rmse <loss>=0.8628805811953094\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=89, batch=0 train mse <loss>=0.744562897403955\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=89, batch=0 train absolute_loss <loss>=0.6675507758464851\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:16.756] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 180, \"duration\": 209, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=89, train rmse <loss>=0.949900057691132\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=89, train mse <loss>=0.9023101196016158\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=89, train absolute_loss <loss>=0.7186308395348218\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150236.5446227, \"EndTime\": 1706150236.7572784, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 211.98654174804688, \"count\": 1, \"min\": 211.98654174804688, \"max\": 211.98654174804688}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #progress_metric: host=algo-1, completed 98.9010989010989 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150236.5452673, \"EndTime\": 1706150236.7574866, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 89, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6353644.0, \"count\": 1, \"min\": 6353644, \"max\": 6353644}, \"Total Batches Seen\": {\"sum\": 6481.0, \"count\": 1, \"min\": 6481, \"max\": 6481}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=332445.047645356 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=90, batch=0 train rmse <loss>=0.862119604068679\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=90, batch=0 train mse <loss>=0.743250211719536\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=90, batch=0 train absolute_loss <loss>=0.6668028802699006\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:16.972] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 182, \"duration\": 212, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=90, train rmse <loss>=0.9491462574304951\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=90, train mse <loss>=0.9008786179943157\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, epoch=90, train absolute_loss <loss>=0.7179379555940788\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, train rmse <loss>=0.9491462574304951\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, train mse <loss>=0.9008786179943157\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #quality_metric: host=algo-1, train absolute_loss <loss>=0.7179379555940788\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150236.7573392, \"EndTime\": 1706150236.97269, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 214.82181549072266, \"count\": 1, \"min\": 214.82181549072266, \"max\": 214.82181549072266}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150236.7578459, \"EndTime\": 1706150236.9729044, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 90, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6424229.0, \"count\": 1, \"min\": 6424229, \"max\": 6424229}, \"Total Batches Seen\": {\"sum\": 6553.0, \"count\": 1, \"min\": 6553, \"max\": 6553}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 92.0, \"count\": 1, \"min\": 92, \"max\": 92}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] #throughput_metric: host=algo-1, train throughput=328038.359891014 records/second\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 WARNING 140081874167616] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150236.972775, \"EndTime\": 1706150236.975964, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 2.810239791870117, \"count\": 1, \"min\": 2.810239791870117, \"max\": 2.810239791870117}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:16 INFO 140081874167616] Saved checkpoint to \"/tmp/tmp6mtre_2i/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:16.980] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 20916, \"num_examples\": 1, \"num_bytes\": 63616}\u001b[0m\n",
      "\u001b[34m[2024-01-25 02:37:17.042] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 61, \"num_examples\": 31, \"num_bytes\": 1936064}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150236.9805825, \"EndTime\": 1706150237.0426614, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"test_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 30251.0, \"count\": 1, \"min\": 30251, \"max\": 30251}, \"Total Batches Seen\": {\"sum\": 31.0, \"count\": 1, \"min\": 31, \"max\": 31}, \"Max Records Seen Between Resets\": {\"sum\": 30251.0, \"count\": 1, \"min\": 30251, \"max\": 30251}, \"Max Batches Seen Between Resets\": {\"sum\": 31.0, \"count\": 1, \"min\": 31, \"max\": 31}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 30251.0, \"count\": 1, \"min\": 30251, \"max\": 30251}, \"Number of Batches Since Last Reset\": {\"sum\": 31.0, \"count\": 1, \"min\": 31, \"max\": 31}}}\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:17 INFO 140081874167616] #test_score (algo-1) : ('rmse', 0.9069811409492536)\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:17 INFO 140081874167616] #test_score (algo-1) : ('mse', 0.8226147900376098)\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:17 INFO 140081874167616] #test_score (algo-1) : ('absolute_loss', 0.7209633612237896)\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:17 INFO 140081874167616] #quality_metric: host=algo-1, test rmse <loss>=0.9069811409492536\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:17 INFO 140081874167616] #quality_metric: host=algo-1, test mse <loss>=0.8226147900376098\u001b[0m\n",
      "\u001b[34m[01/25/2024 02:37:17 INFO 140081874167616] #quality_metric: host=algo-1, test absolute_loss <loss>=0.7209633612237896\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1706150236.976011, \"EndTime\": 1706150237.043416, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 15.280961990356445, \"count\": 1, \"min\": 15.280961990356445, \"max\": 15.280961990356445}, \"totaltime\": {\"sum\": 21000.454425811768, \"count\": 1, \"min\": 21000.454425811768, \"max\": 21000.454425811768}}}\u001b[0m\n",
      "\n",
      "2024-01-25 02:37:31 Uploading - Uploading generated training model\n",
      "2024-01-25 02:37:31 Completed - Training job completed\n",
      "Training seconds: 307\n",
      "Billable seconds: 138\n",
      "Managed Spot Training savings: 55.0%\n"
     ]
    }
   ],
   "source": [
    "# New Hyperparameters\n",
    "# Reference: Supported channels by algorithm\n",
    "#   https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html\n",
    "estimator.fit({'train':s3_training_file_location, 'test': s3_test_file_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: fm-movie-v4-2024-01-25-03-07-25-569\n",
      "INFO:sagemaker:Creating endpoint-config with name fm-movie-v4\n",
      "INFO:sagemaker:Creating endpoint with name fm-movie-v4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "# Ref: http://sagemaker.readthedocs.io/en/latest/estimators.html\n",
    "predictor = estimator.deploy(initial_instance_count=1,\n",
    "                             instance_type='ml.m5.xlarge',\n",
    "                             endpoint_name = job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Predictions\n",
    "### Dense and Sparse Formats\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-inference.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def fm_sparse_serializer(data):\n",
    "    js = {'instances': []}\n",
    "    for row in data:\n",
    "        \n",
    "        column_list = row.tolist()\n",
    "        value_list = np.ones(len(column_list),dtype=int).tolist()\n",
    "       \n",
    "        js['instances'].append({'data':{'features': { 'keys': column_list, 'shape':[dim_movie], 'values': value_list}}})\n",
    "    return json.dumps(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SDK 2\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/factorization_machines_mnist/factorization_machines_mnist.ipynb\n",
    "\n",
    "# Specify custom serializer\n",
    "predictor.serializer.serialize = fm_sparse_serializer\n",
    "predictor.serializer.content_type = 'application/json'\n",
    "\n",
    "predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"instances\": [{\"data\": {\"features\": {\"keys\": [341, 1416], \"shape\": [10334], \"values\": [1, 1]}}}]}'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_sparse_serializer([np.array([341,1416])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie ['2.5', '426:1', '943:1']\n",
      "  Actual Rating:\t2.5\n",
      "  Predicted Rating:\t2.8515758514404297\n",
      "\n",
      "Movie ['3', '110:1', '10120:1']\n",
      "  Actual Rating:\t3\n",
      "  Predicted Rating:\t3.107433795928955\n",
      "\n",
      "Movie ['4', '304:1', '1554:1']\n",
      "  Actual Rating:\t4\n",
      "  Predicted Rating:\t4.020742416381836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's test with few entries from test file\n",
    "# Movie dataset is updated regularly...so, instead of hard coding userid and movie id, let's\n",
    "# use actual values\n",
    "\n",
    "# Each row is in this format: ['2.5', '426:1', '943:1']\n",
    "# ActualRating, UserID, MovieID\n",
    "\n",
    "with open(r'ml-latest-small/user_movie_test.svm','r') as f:\n",
    "    for i in range(3):\n",
    "        rating = f.readline().split()\n",
    "        print(f\"Movie {rating}\")\n",
    "        userID = rating[1].split(':')[0]\n",
    "        movieID = rating[2].split(':')[0]\n",
    "        predicted_rating = predictor.predict([np.array([int(userID),int(movieID)])])\n",
    "        print(f'  Actual Rating:\\t{rating[0]}')\n",
    "        print(f\"  Predicted Rating:\\t{predicted_rating['predictions'][0]['score']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ensure Training, Test and Validation data are in S3 Bucket\n",
    "2. Select Algorithm Container Registry Path - Path varies by region\n",
    "3. Configure Estimator for training - Specify Algorithm container, instance count, instance type, model output location\n",
    "4. Specify algorithm specific hyper parameters\n",
    "5. Train model\n",
    "6. Deploy model - Specify instance count, instance type and endpoint name\n",
    "7. Run Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
